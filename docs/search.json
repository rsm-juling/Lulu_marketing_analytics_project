[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lulu Ling",
    "section": "",
    "text": "Hi!! I am Lulu Ling. This is my marketing analytics project."
  },
  {
    "objectID": "Resume.html",
    "href": "Resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\nYour Name\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/Project1/index.html",
    "href": "blog/Project1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn oreder to explore if the price affects on chartibal giving behavior, Dean Karlan and John conducted a large scale experiment involving about 50,000 donors to a liberal nonprofit organization. The subjects were randomly assigned to two groups: a control group and an experimental group. The control group received a standard fundraising letter without any additional instructions, while the experimental group received a letter containing a matching grant.\nIn this experiment, people are further randomly assigned to different sub-treatment conditions, such as designs of matching ratio, matching amount cap and suggested donation amount. These details will be further described in the data description section. The group of treatment will receive letters included an additional paragraph inserted at the top of the second page that announced that a “concerned fellow member” will match their donation, and the reply card included in bold type the details of the match. For the control group, the reply card match language was replaced with a large logo of the organization.\nThis design allows researchers to not only estimate the average treatment effect, but also to further analyze the impact of different matching ratios, upper limits, and recommended amounts on donation decisions. In addition, the study also observed differential responses in red states and blue states, indicating that the political environment also affects the sensitivity of donation behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/Project1/index.html#section-1-data",
    "href": "blog/Project1/index.html#section-1-data",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data"
  },
  {
    "objectID": "blog/Project1/index.html#section-2-analysis",
    "href": "blog/Project1/index.html#section-2-analysis",
    "title": "This is Project 1",
    "section": "",
    "text": "I analyzed the data"
  },
  {
    "objectID": "blog/Project1/index.html#introduction",
    "href": "blog/Project1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn oreder to explore if the price affects on chartibal giving behavior, Dean Karlan and John conducted a large scale experiment involving about 50,000 donors to a liberal nonprofit organization. The subjects were randomly assigned to two groups: a control group and an experimental group. The control group received a standard fundraising letter without any additional instructions, while the experimental group received a letter containing a matching grant.\nIn this experiment, people are further randomly assigned to different sub-treatment conditions, such as designs of matching ratio, matching amount cap and suggested donation amount. These details will be further described in the data description section. The group of treatment will receive letters included an additional paragraph inserted at the top of the second page that announced that a “concerned fellow member” will match their donation, and the reply card included in bold type the details of the match. For the control group, the reply card match language was replaced with a large logo of the organization.\nThis design allows researchers to not only estimate the average treatment effect, but also to further analyze the impact of different matching ratios, upper limits, and recommended amounts on donation decisions. In addition, the study also observed differential responses in red states and blue states, indicating that the political environment also affects the sensitivity of donation behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/Project1/index.html#data",
    "href": "blog/Project1/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThis data comes from a large-scale natural field experiment conducted by a liberal nonprofit organization in the United States in 2005. The purpose of the study was to explore:\nDo different donation reminder designs affect people’s actual donation behavior?\nTreatment Conditions - Paired ratios: $1:$1, $2:$1, $3:$1, control - Maximum amount of matching: $25,000 / $50,000 / $100,000 / control - Ask amount: based on 1.0 times, 1.25 times, or 1.5 times the donor’s highest past donation\nSample size and groups - Total sample size: 50,083 donors - Control group: 16,687 people (33%) - Treatment group: 33,396 people (67%)\nThe fundraising letter received contains instructions for matching donations and is randomly assigned to different matching ratio/maximum amount/suggested amount combinations\nLoading dataset\n\nimport pandas as pd\ndata = pd.read_stata('/home/jovyan/Desktop/UCSD/Spring/MGTA495/lulu_marketing_analytics/blog/Project1/karlan_list_2007.dta')\ndata.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nSplit the data into treatment and control groups\n\ntreatment_data = data[data['treatment'] == 1]\ncontrol_data = data[data['treatment'] == 0]\n\nT-test for mrm2\n\ntreatment_mrm2 = [x for x in treatment_data['mrm2'] if x == x]\ncontrol_mrm2 = [x for x in control_data['mrm2'] if x == x]\n\nn1 = len(treatment_mrm2)\nn2 = len(control_mrm2)\n\nmean1 = sum(treatment_mrm2) / n1\nmean2 = sum(control_mrm2) / n2\n\nvar1 = sum((x - mean1)**2 for x in treatment_mrm2) / (n1 - 1)\nvar2 = sum((x - mean2)**2 for x in control_mrm2) / (n2 - 1)\n\nse = ((var1 / n1) + (var2 / n2)) ** 0.5\n\nt_stat = (mean1 - mean2) / se\nprint(f\"t-statistic = {round(t_stat, 4)}\")\n\nt-statistic = 0.1195\n\n\nLinear regression for mrm2\n\nimport statsmodels.api as sm\n\ndata['intercept'] = 1 \nmodel = sm.OLS(data['mrm2'], data[['intercept', 'treatment']], missing='drop').fit()\nprint(model.summary())\n\nregression_t_stat, regression_p_value = model.tvalues['treatment'].round(4), model.pvalues['treatment']\nprint(f\"t-statistic: {regression_t_stat}\")\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.905\nTime:                        00:58:20   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nt-statistic: 0.1195\n\n\nTable 1 is used to assess whether the experimental random assignment was successful. It compares the treatment and control groups on background variables such as past donation behavior, demographics, and political region. Since these factors should not be influenced by the treatment, the goal is to show that both groups were similar before the experiment, ensuring that later differences in donation behavior can be attributed to the treatment itself rather than pre-existing differences.\nThe results of t-test and linear regression analysis are consistent with Table 1 in the paper. Table 1 is designed to show that before the experiment, the distributions of the treatment and control groups on a series of background variables are very similar. This is critical because if the two groups differ on these variables, then the experimental results cannot be attributed simply to the effect of the treatment, but may be caused by differences in the sample composition. But now we see that there is no significant difference in the variable mrm2 between the two groups, which provides evidence that the randomization of the experiment was successful. Therefore, we can reasonably infer that the subsequent differences in donation behavior are more likely caused by the paired donation prompt (treatment) rather than the differences in the original background conditions between the two groups."
  },
  {
    "objectID": "blog/Project1/index.html#experimental-results",
    "href": "blog/Project1/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\nBar plot of the proportion of peole donated between treatment and controal group.\n\nimport matplotlib.pyplot as plt\n\ntreatment_prop = treatment_data['gave'].mean()\ncontrol_prop = control_data['gave'].mean()\n\nplt.bar(['Treatment', 'Control'], [treatment_prop, control_prop], color=['pink', 'lightblue'])\nplt.ylabel('Proportion of People Who Donated')\nplt.title('Proportion of Donors in Treatment and Control')\nplt.show()\n\n\n\n\n\n\n\n\nT test: compare whether there is a significant difference in the donation rate between the treatment and control groups\n\nfrom scipy.stats import ttest_ind\ntreatment_gave = treatment_data['gave']\ncontrol_gave = control_data['gave']\nt_stat_gave, p_value_gave = ttest_ind(treatment_gave, control_gave, equal_var=False)\nprint(f\"t-statistic = {t_stat_gave.round(4)}, p-value = {p_value_gave.round(4)}\")\n\nt-statistic = 3.2095, p-value = 0.0013\n\n\nWe first conducted an independent sample t-test on the binary variable gave. The results showed that the t-value and the p-value indicating that the difference in donation rates between the treatment group and the control group was statistically significant at a 95% confidence level. This suggests that simply including the phrase “your donation will be matched” in your fundraising email can significantly increase donation rates.\nLinear regression: Using OLS to test the effect of treatment on donation behavior\n\ngave_model = sm.OLS(data['gave'], data[['intercept', 'treatment']], missing='drop').fit()\nprint(gave_model.summary())\nprint(f\"t-statistic = {gave_model.tvalues['treatment'].round(4)},p-value = {gave_model.pvalues['treatment'].round(4)}\" )\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):            0.00193\nTime:                        00:58:20   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nt-statistic = 3.1014,p-value = 0.0019\n\n\nTo verify this, we used simple linear regression with gave as the dependent variable and treatment as the independent variable. The results showed that the t-value and p-value were almost consistent with the t-test results, proving that the two methods are consistent when analyzing this type of binary outcome variable.\nThe proportion of respsonse rate in control gorup and treatment group\n\nprint(f\"Control Proportion: {control_prop:.3f}\")\nprint(f\"Treatment Proportion: {treatment_prop:.3f}\")\n\nControl Proportion: 0.018\nTreatment Proportion: 0.022\n\n\nThis result is also consistent with the data in Table 2A of the original text (1.8% in the control group and 2.2% in the experimental group). From a behavioral economics perspective, this stable difference may be because when people see the message that “your donation will be matched,” they feel that their donation is more valuable and more influential. This feeling will make them more willing to donate. It’s like people feel a sense of satisfaction when they donate, and the message of matching donations makes this satisfaction even stronger, thus increasing their willingness to act.\nOverall, this analysis supports the original authors’ conclusion: even without changing the amount, providing matching information can effectively increase the likelihood of donations, which has important implications for practical fundraising strategies.\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\nProbit Regression: Estimating the Effect of Pairing Prompts on the Probability of Donating\n\nprobit_model = sm.Probit(data['gave'], data[['intercept', 'treatment']])\nprobit_results = probit_model.fit()\nprint(probit_results.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        00:58:20   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\nMarginal effect analysis: explaining the actual effect of treatment on the probability of donating\n\nmarginal_effects = probit_results.get_margeff()\nprint(marginal_effects.summary())\n\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment      0.0043      0.001      3.104      0.002       0.002       0.007\n==============================================================================\n\n\nThe results are completely consistent with column 1 of Table 3 , successfully replicating the reported analysis. This means that the pairing prompt can significantly increase the probability of people donating, and even if the effect is small, it is statistically stable and significant. In the Probit model, the original coefficient cannot be directly interpreted as “how much the donation rate increased”, but it can be converted into a marginal effect. We can see from the Probit marginal effect model that the result is 0.0043, which corresponds exactly to 0.004 in the first column of Table 3.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nT-tests for match ratio effects on donation\n\nr1 = treatment_data[treatment_data['ratio'] == 1]\nr2 = treatment_data[treatment_data['ratio'] == 2]\nr3 = treatment_data[treatment_data['ratio'] == 3]\n\nt_stat_1v2, p_value_1v2 = ttest_ind(r1['gave'], r2['gave'], equal_var=False)\nt_stat_2v3, p_value_2v3 = ttest_ind(r2['gave'], r3['gave'], equal_var=False)\n\nprint(f\"T-test 1:1 vs 2:1 - t-statistic: {t_stat_1v2:.4f}, p-value: {p_value_1v2:.4f}\")\nprint(f\"T-test 2:1 vs 3:1 - t-statistic: {t_stat_2v3:.4f}, p-value: {p_value_2v3:.4f}\")\n\nT-test 1:1 vs 2:1 - t-statistic: -0.9650, p-value: 0.3345\nT-test 2:1 vs 3:1 - t-statistic: -0.0501, p-value: 0.9600\n\n\nIn the paired donation prompt group, there were no significant behavioral differences between the different pairing ratios (1:1, 2:1, and 3:1).The t-value of the 1:1 and 2:1 groups is -0.965, and the p-value is 0.3345, indicating that we cannot reject the null hypothesis and there is no statistically significant difference in the donation rates between the two groups. The difference between the 2:1 and 3:1 groups is even smaller, with a t-value of only -0.0501 and a corresponding p-value of 0.96, indicating that there is no difference in donation behavior between the two groups.\nThe analysis results of the t-test support the author’s observations on page 8 of the paper. The authors note that while the pairing prompt itself increased donation rates, further increasing the pairing ratio (from 1:1 to 2:1 or 3:1) in the pairing prompt group did not lead to additional effects. The t-test you conducted also clearly reflects this point: the difference in donation rates between different matching ratios is not statistically significant, and the p-values ​​are all far higher than the traditional significance level, especially the difference between 2:1 and 3:1 is almost zero. This shows that in actual donation behavior, people are more sensitive to whether there is a match rather than the size of the matching ratio.\nRegression analysis for match ratio effects\n\ndata['ratio1'] = (data['ratio'] == 1).astype(int)\n\nratio_model = sm.OLS(data['gave'], data[['intercept', 'ratio1', 'ratio2', 'ratio3']], missing='drop').fit()\nprint(ratio_model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.665\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0118\nTime:                        00:58:20   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.322e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.0179      0.001     16.225      0.000       0.016       0.020\nratio1         0.0029      0.002      1.661      0.097      -0.001       0.006\nratio2         0.0048      0.002      2.744      0.006       0.001       0.008\nratio3         0.0049      0.002      2.802      0.005       0.001       0.008\n==============================================================================\nOmnibus:                    59812.754   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4316693.217\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.438   Cond. No.                         4.26\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nAccording to the regression results, we observed that different pairing ratios do have an impact on donation behavior, but the strength of the effect varies. The donation rate for ratio1 is about 0.29 percentage points higher, which is positive but only slightly statistically significant. The effects of the paired groups of ratio2 and ratio3 are more obvious, with the donation rates being approximately 0.48 and 0.49 percentage points higher than the benchmark group, respectively, and are significant at the 1% significance level.\nThis means that as long as there is matching information, even ratio 1 may increase people’s willingness to donate, and increasing the matching ratio to ratio 2 or ratio 3 will further strengthen this incentive. However, the effects of ratio2 and ratio3 are similar and almost the same, indicating that the marginal benefit of increasing the pairing ratio tends to be flat or saturated. This is consistent with the authors’ observation in the paper that higher pairing ratios do not necessarily produce additional significant behavioral changes.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\nResponse rate differences\n\nresp_rate_1 = r1['gave'].mean()\nresp_rate_2 = r2['gave'].mean()\nresp_rate_3 = r3['gave'].mean()\n\ndiff_1v2 = resp_rate_2 - resp_rate_1\ndiff_2v3 = resp_rate_3 - resp_rate_2\n\nprint(f\"Response rate difference 1:1 vs 2:1: {diff_1v2:.4f}\")\nprint(f\"Response rate difference 2:1 vs 3:1: {diff_2v3:.4f}\")\n\nResponse rate difference 1:1 vs 2:1: 0.0019\nResponse rate difference 2:1 vs 3:1: 0.0001\n\n\nThe difference between the donation rates is very small, and further increasing the matching ratio, for example from ratio1 to ratio2 or ratio3, has very limited effect on the donation rate.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nT-test for donation amount\n\ntreatment_amount = treatment_data['amount'].dropna()\ncontrol_amount = control_data['amount'].dropna()\nt_stat_amount, p_value_amount = ttest_ind(treatment_amount, control_amount, equal_var=False)\nprint(f\"T-test for donation amount: t-statistic = {t_stat_amount:.4f}, p-value = {p_value_amount:.4f}\")\n\nT-test for donation amount: t-statistic = 1.9183, p-value = 0.0551\n\n\nBivariate linear regression for donation amount\n\namount_model = sm.OLS(data['amount'], data[['intercept', 'treatment']], missing='drop').fit()\nprint(amount_model.summary())\nprint(f\"t-statistic = {amount_model.tvalues['treatment']:.4f}, p-value = {amount_model.pvalues['treatment']:.4f}\")\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0628\nTime:                        00:58:20   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nt-statistic = 1.8605, p-value = 0.0628\n\n\nWhen we analyzed the donation amount, both the independent sample t-test and the bivariate linear regression showed that the average donation amount of the treatment group was slightly higher than that of the control group, but the difference was only marginally significant. The p-value of the t-test is 0.0551, and the p-value of the regression is 0.063, both slightly higher than the traditional 5% significance level.\nOverall, the matching prompt has a clear impact on whether to donate, while the impact of amount is weaker. From a behavioral perspective, the matching message is more like a “motivation switch” that prompts people to take action rather than a reinforcement tool that influences the amount of donations. This also means that in terms of fundraising strategy, matching donations are more suitable as an incentive to guide donation behavior rather than a means to increase the single amount.\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\nConditional donation amount regression analysis: evaluating the impact and explanatory power of matching prompts only for actual donors\n\ndonors = data[data['amount'] &gt; 0]\n\ndonors_model = sm.OLS(donors['amount'], donors[['intercept', 'treatment']], missing='drop').fit()\nprint(donors_model.summary())\n\ntreatment_coef = donors_model.params['treatment']\nprint(f\"Treatment coefficient: {treatment_coef:.4f}\")\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.561\nTime:                        00:58:20   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nTreatment coefficient: -1.6684\n\n\nIn this regression analysis of those who have already donated, the treatment coefficient is -1.6684, it means that the average donation amount of the treatment group is about 1.67 yuan lower than that of the control group., however, this result is not statistically significant because the p-value is only 0.561, indicating that the matching prompt has no stable effect on the amount donated by those who have already decided to donate. It should be noted that this regression result cannot be interpreted as a causal effect of treatment on the amount of donations, because the analysis is limited to people who actually donated. This is a conditional subsample and not a random assignment, so there is a risk of selection bias. Taken together, our findings suggest that matching donation prompts are more likely to influence the behavior of whether to donate rather than the amount of donation.\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\nCompare the distribution of donations between treatment and control groups (limited to donors)\n\n# Filter data for donors only\ntreatment_donors = treatment_data[treatment_data['amount'] &gt; 0]\ncontrol_donors = control_data[control_data['amount'] &gt; 0]\n\n# Calculate sample averages\ntreatment_avg = treatment_donors['amount'].mean()\ncontrol_avg = control_donors['amount'].mean()\n\n# Plot histograms\nfig, axes = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n\n# Treatment group histogram\naxes[0].hist(treatment_donors['amount'], bins=30, color='skyblue', alpha=0.7)\naxes[0].axvline(treatment_avg, color='red', linestyle='--', label=f'Avg: {treatment_avg:.2f}')\naxes[0].set_title('Treatment Group: Donation Amounts')\naxes[0].set_xlabel('Donation Amount')\naxes[0].set_ylabel('Frequency')\naxes[0].legend()\n\n# Control group histogram\naxes[1].hist(control_donors['amount'], bins=30, color='pink', alpha=0.7)\naxes[1].axvline(control_avg, color='red', linestyle='--', label=f'Avg: {control_avg:.2f}')\naxes[1].set_title('Control Group: Donation Amounts')\naxes[1].set_xlabel('Donation Amount')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "blog/Project1/index.html#simulation-experiment",
    "href": "blog/Project1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nSimulation of the Law of Large Numbers: Cumulative Average Difference in Donation Rates\n\nimport numpy as np\n#calculation\nnp.random.seed(42)\ncontrol_draws = np.random.binomial(n=1, p=0.018, size=100000)\ntreatment_draws = np.random.binomial(n=1, p=0.022, size=10000)\ncontrol_sample = np.random.choice(control_draws, size=10000, replace=False)\ndiff = treatment_draws - control_sample\ncumulative_avg = np.cumsum(diff) / np.arange(1, len(diff) + 1)\n#plot\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg, label=\"Cumulative mean difference\")\nplt.axhline(y=0.004, color='red', linestyle='--', label=\"Theoretical mean difference = 0.004\")\nplt.title(\"Simulation: Cumulative Average Difference in Donation Rates)\")\nplt.xlabel(\"Sample Size\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis graph shows the difference in donation rates between the treatment group and the control group, calculated through simulations, as the number of samples increases. As can be seen from the figure, although the difference fluctuates greatly when the number of samples is small, as the number of samples gradually increases, the cumulative average curve steadily approaches the theoretical true difference value of 0.004.\nThis is a typical manifestation of the Law of Large Numbers: when we observe enough samples, the mean of the samples will approach the true mean of the population. This also means that the difference in donation rates observed in the original experiment (the slightly higher donation rate in the treatment group than in the control group) was not caused by random errors, but was a stable and reproducible result.\nTherefore, we can reasonably say that the simulation results in this figure verify the stability and credibility of the treatment effect and provide strong visual evidence to support that the observations in the experiment are reliable.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”\n\nimport numpy as np\n\ncontrol_draws = np.random.binomial(1, 0.018, 100000)\ntreatment_draws = np.random.binomial(1, 0.022, 10000)\nsample_sizes = [50, 200, 500, 1000]\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\naxes = axes.flatten()\n\nfor i, sample_size in enumerate(sample_sizes):\n    avg_differences = []\n\n    for _ in range(1000):\n        treatment_sample = np.random.choice(treatment_draws, size=sample_size, replace=True)\n        control_sample = np.random.choice(control_draws, size=sample_size, replace=True)\n        avg_differences.append(np.mean(treatment_sample - control_sample))\n\n    axes[i].hist(avg_differences, bins=30, color='pink', edgecolor='black', alpha=0.7)\n    axes[i].axvline(0, color='red', linestyle='--', label='Zero')\n    axes[i].set_title(f'Sample Size: {sample_size}')\n    axes[i].set_xlabel('Average Difference')\n    axes[i].set_ylabel('Frequency')\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThese four histograms show the simulated distribution changes of the difference in donation rates between the treatment group and the control group under different sample sizes (50, 200, 500, 1000). When the sample size is small, the distribution is more dispersed, and 0 almost falls in the center, which means that it is impossible to determine whether the treatment effect is significant. However, as the number of samples increases, the distribution begins to become concentrated and biased toward positive differences, especially when the number of samples reaches 500 or 1000, when 0 is clearly off the center and falls in the left tail of the distribution. This means that when the sample size is sufficient, the treatment group does show a stable and positive effect, and the average donation rate is higher than that of the control group. This difference is unlikely to be caused by random errors. Overall, this set of charts reinforces a basic principle in statistical inference: the larger the sample size, the more stable the results and the more reliably they reveal true behavioral differences."
  },
  {
    "objectID": "blog/Project1/hw1_questions.html",
    "href": "blog/Project1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/Project1/hw1_questions.html#introduction",
    "href": "blog/Project1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/Project1/hw1_questions.html#data",
    "href": "blog/Project1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "blog/Project1/hw1_questions.html#experimental-results",
    "href": "blog/Project1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "blog/Project1/hw1_questions.html#simulation-experiment",
    "href": "blog/Project1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "blog/Project1/project1.html",
    "href": "blog/Project1/project1.html",
    "title": "Lulu's Marketing Analytics Project",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport os\n\n\ndata = pd.read_stata('/home/jovyan/Desktop/UCSD/Spring/MGTA495/lulu_marketing_analytics/blog/Project1/karlan_list_2007.dta')\ndata\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.688262\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\n0.900000\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.917206\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.530023\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\n\n\n\n\n50083 rows × 51 columns\n\n\n\n\ndata.to_excel('output_data.xlsx', index=False)\n\n\ntreatment_data = data[data['treatment'] == 1]\n\n\ncontrol_data = data[data['treatment'] == 0]\n\n\nfrom scipy.stats import ttest_ind\n\n# T-test for mrm2\ntreatment_mrm2 = treatment_data['mrm2'].dropna()\ncontrol_mrm2 = control_data['mrm2'].dropna()\nt_stat, p_value = ttest_ind(treatment_mrm2, control_mrm2, equal_var=False)\nprint(f\"T-test for mrm2: t-statistic = {t_stat.round(4)}, p-value = {p_value.round(4)}\")\n\nT-test for mrm2: t-statistic = 0.1195, p-value = 0.9049\n\n\n\n# 去除缺漏值\ntreatment_mrm2 = [x for x in treatment_data['mrm2'] if x == x]\ncontrol_mrm2 = [x for x in control_data['mrm2'] if x == x]\n\n# 計算樣本數\nn1 = len(treatment_mrm2)\nn2 = len(control_mrm2)\n\n# 計算平均\nmean1 = sum(treatment_mrm2) / n1\nmean2 = sum(control_mrm2) / n2\n\n# 計算變異數（無偏估計，分母用 n-1）\nvar1 = sum((x - mean1)**2 for x in treatment_mrm2) / (n1 - 1)\nvar2 = sum((x - mean2)**2 for x in control_mrm2) / (n2 - 1)\n\n# 計算標準誤\nse = ((var1 / n1) + (var2 / n2)) ** 0.5\n\n# 計算 t 統計量\nt_stat = (mean1 - mean2) / se\n\nprint(f\"T-test (by formula) for mrm2: t-statistic = {round(t_stat, 4)}\")\n\nT-test (by formula) for mrm2: t-statistic = 0.1195\n\n\n\nimport statsmodels.api as sm\n\n# Linear regression for mrm2\ndata['intercept'] = 1 \nmodel = sm.OLS(data['mrm2'], data[['intercept', 'treatment']], missing='drop').fit()\nprint(model.summary())\n# Extract the t-statistic for the 'treatment' coefficient from the regression model\nregression_t_stat = model.tvalues['treatment'].round(4)\nprint(f\"Regression model t-statistic: {regression_t_stat}\")\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):              0.905\nTime:                        16:22:47   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nRegression model t-statistic: 0.1195\n\n\n\nimport matplotlib.pyplot as plt\n\ntreatment_proportion = treatment_data['gave'].mean()\ncontrol_proportion = control_data['gave'].mean()\n\nplt.bar(['Treatment', 'Control'], [treatment_proportion, control_proportion], color=['pink', 'lightblue'])\nplt.ylabel('Proportion of People Who Donated')\nplt.title('Proportion of Donors by Group')\nplt.show()\n\n\n\n\n\n\n\n\n\n# T-test for the binary outcome 'gave'\ntreatment_gave = treatment_data['gave']\ncontrol_gave = control_data['gave']\nt_stat_gave, p_value_gave = ttest_ind(treatment_gave, control_gave, equal_var=False)\nprint(f\"T-test for 'gave': t-statistic = {t_stat_gave.round(4)}, p-value = {p_value_gave.round(4)}\")\n\n# Bivariate linear regression for 'gave'\ngave_model = sm.OLS(data['gave'], data[['intercept', 'treatment']], missing='drop').fit()\nprint(gave_model.summary())\nprint(f\"Linear regression for 'gave': t-statistic = {gave_model.tvalues['treatment'].round(4)}\")\n\nT-test for 'gave': t-statistic = 3.2095, p-value = 0.0013\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):            0.00193\nTime:                        16:22:47   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nLinear regression for 'gave': t-statistic = 3.1014\n\n\n\nprint(f\"Control Proportion: {control_proportion:.3f}\")\nprint(f\"Treatment Proportion: {treatment_proportion:.3f}\")\n\nControl Proportion: 0.018\nTreatment Proportion: 0.022\n\n\n\n# Probit regression for charitable donation\nprobit_model = sm.Probit(data['gave'], data[['intercept', 'treatment']])\nprobit_results = probit_model.fit()\nprint(probit_results.summary())\n\n# 邊際效應估計\nmarginal_effects = probit_results.get_margeff()\nprint(marginal_effects.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Tue, 22 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        00:08:21   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment      0.0043      0.001      3.104      0.002       0.002       0.007\n==============================================================================\n\n\n\nfrom scipy.stats import ttest_ind\n\n# Task 1: T-tests for match ratio effects on donation likelihood\n\n# Filter data for each match ratio\nratio1_data = treatment_data[treatment_data['ratio'] == 1]\nratio2_data = treatment_data[treatment_data['ratio'] == 2]\nratio3_data = treatment_data[treatment_data['ratio'] == 3]\n\n# Perform t-tests\nt_stat_1v2, p_value_1v2 = ttest_ind(ratio1_data['gave'], ratio2_data['gave'], equal_var=False)\nt_stat_2v3, p_value_2v3 = ttest_ind(ratio2_data['gave'], ratio3_data['gave'], equal_var=False)\n\nprint(f\"T-test 1:1 vs 2:1 - t-statistic: {t_stat_1v2:.4f}, p-value: {p_value_1v2:.4f}\")\nprint(f\"T-test 2:1 vs 3:1 - t-statistic: {t_stat_2v3:.4f}, p-value: {p_value_2v3:.4f}\")\n\n\n\n\nT-test 1:1 vs 2:1 - t-statistic: -0.9650, p-value: 0.3345\nT-test 2:1 vs 3:1 - t-statistic: -0.0501, p-value: 0.9600\n\n\n\ndata['ratio1'] = (data['ratio'] == 1).astype(int)\n\nratio_model = sm.OLS(data['gave'], data[['intercept', 'ratio1', 'ratio2', 'ratio3']], missing='drop').fit()\nprint(ratio_model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.665\nDate:                Tue, 22 Apr 2025   Prob (F-statistic):             0.0118\nTime:                        11:02:58   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.322e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.0179      0.001     16.225      0.000       0.016       0.020\nratio1         0.0029      0.002      1.661      0.097      -0.001       0.006\nratio2         0.0048      0.002      2.744      0.006       0.001       0.008\nratio3         0.0049      0.002      2.802      0.005       0.001       0.008\n==============================================================================\nOmnibus:                    59812.754   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4316693.217\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.438   Cond. No.                         4.26\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n# Task 3: Response rate differences\n# Direct calculation from data\nresponse_rate_1 = ratio1_data['gave'].mean()\nresponse_rate_2 = ratio2_data['gave'].mean()\nresponse_rate_3 = ratio3_data['gave'].mean()\n\ndiff_1v2 = response_rate_2 - response_rate_1\ndiff_2v3 = response_rate_3 - response_rate_2\n\nprint(f\"Response rate difference 1:1 vs 2:1: {diff_1v2:.4f}\")\nprint(f\"Response rate difference 2:1 vs 3:1: {diff_2v3:.4f}\")\n\nResponse rate difference 1:1 vs 2:1: 0.0019\nResponse rate difference 2:1 vs 3:1: 0.0001\n\n\n\n# Differences from regression coefficients\ncoef_diff_1v2 = ratio_model.params['ratio2'] - ratio_model.params['ratio1']\ncoef_diff_2v3 = ratio_model.params['ratio3'] - ratio_model.params['ratio2']\n\nprint(f\"Coefficient difference 1:1 vs 2:1: {coef_diff_1v2:.4f}\")\nprint(f\"Coefficient difference 2:1 vs 3:1: {coef_diff_2v3:.4f}\")\n\nCoefficient difference 1:1 vs 2:1: 0.0019\nCoefficient difference 2:1 vs 3:1: 0.0001\n\n\n\n# T-test for donation amount\ntreatment_amount = treatment_data['amount'].dropna()\ncontrol_amount = control_data['amount'].dropna()\nt_stat_amount, p_value_amount = ttest_ind(treatment_amount, control_amount, equal_var=False)\nprint(f\"T-test for donation amount: t-statistic = {t_stat_amount:.4f}, p-value = {p_value_amount:.4f}\")\n\n# Bivariate linear regression for donation amount\namount_model = sm.OLS(data['amount'], data[['intercept', 'treatment']], missing='drop').fit()\nprint(amount_model.summary())\nprint(f\"Linear regression for donation amount: t-statistic = {amount_model.tvalues['treatment']:.4f}, p-value = {amount_model.pvalues['treatment']:.4f}\")\n\nT-test for donation amount: t-statistic = 1.9183, p-value = 0.0551\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):             0.0628\nTime:                        16:22:48   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nLinear regression for donation amount: t-statistic = 1.8605, p-value = 0.0628\n\n\n\n# Filter data to include only those who made a donation\ndonors_data = data[data['amount'] &gt; 0]\n\n# Regression analysis for donation amount conditional on donating\ndonors_model = sm.OLS(donors_data['amount'], donors_data[['intercept', 'treatment']], missing='drop').fit()\nprint(donors_model.summary())\n\n# Interpretation of the treatment coefficient\ntreatment_coef = donors_model.params['treatment']\nprint(f\"Treatment coefficient: {treatment_coef:.4f}\")\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):              0.561\nTime:                        16:22:48   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nTreatment coefficient: -1.6684\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 模擬參數\nn_control = 100000\nn_treatment = 10000\np_control = 0.018\np_treatment = 0.022\n\n# 隨機抽樣\nnp.random.seed(42)\ncontrol_draws = np.random.binomial(n=1, p=p_control, size=n_control)\ntreatment_draws = np.random.binomial(n=1, p=p_treatment, size=n_treatment)\n\n# 從控制組中隨機抽出與 treatment 組一樣多的樣本\ncontrol_sample = np.random.choice(control_draws, size=n_treatment, replace=False)\n\n# 計算逐筆差異\ndifferences = treatment_draws - control_sample\n\n# 計算累積平均\ncumulative_avg = np.cumsum(differences) / np.arange(1, len(differences) + 1)\n\n# 繪製圖形\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg, label=\"Cumulative mean difference\")\nplt.axhline(y=0.004, color='red', linestyle='--', label=\"Theoretical mean difference = 0.004\")\nplt.title(\"Simulation: Cumulative Average Difference in Donation Rates)\")\nplt.xlabel(\"Sample Size\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Filter data for donors only\ntreatment_donors = treatment_data[treatment_data['amount'] &gt; 0]\ncontrol_donors = control_data[control_data['amount'] &gt; 0]\n\n# Calculate sample averages\ntreatment_avg = treatment_donors['amount'].mean()\ncontrol_avg = control_donors['amount'].mean()\n\n# Plot histograms\nfig, axes = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n\n# Treatment group histogram\naxes[0].hist(treatment_donors['amount'], bins=30, color='skyblue', alpha=0.7)\naxes[0].axvline(treatment_avg, color='red', linestyle='--', label=f'Avg: {treatment_avg:.2f}')\naxes[0].set_title('Treatment Group: Donation Amounts')\naxes[0].set_xlabel('Donation Amount')\naxes[0].set_ylabel('Frequency')\naxes[0].legend()\n\n# Control group histogram\naxes[1].hist(control_donors['amount'], bins=30, color='pink', alpha=0.7)\naxes[1].axvline(control_avg, color='red', linestyle='--', label=f'Avg: {control_avg:.2f}')\naxes[1].set_title('Control Group: Donation Amounts')\naxes[1].set_xlabel('Donation Amount')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Define sample sizes\nsample_sizes = [50, 200, 500, 1000]\n\n# Initialize a figure for subplots\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\naxes = axes.flatten()\n\n# Loop through each sample size\nfor i, sample_size in enumerate(sample_sizes):\n    avg_differences = []\n    \n    # Simulate 1000 averages\n    for _ in range(1000):\n        treatment_sample = np.random.choice(treatment_draws, size=sample_size, replace=True)\n        control_sample = np.random.choice(control_draws, size=sample_size, replace=True)\n        avg_differences.append(np.mean(treatment_sample - control_sample))\n    \n    # Plot histogram\n    axes[i].hist(avg_differences, bins=30, color='pink', edgecolor='black', alpha=0.7)\n    axes[i].axvline(0, color='red', linestyle='--', label='Zero')\n    axes[i].set_title(f'Sample Size: {sample_size}')\n    axes[i].set_xlabel('Average Difference')\n    axes[i].set_ylabel('Frequency')\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()"
  }
]