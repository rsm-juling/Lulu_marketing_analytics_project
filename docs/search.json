[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lulu Ling",
    "section": "",
    "text": "Hi!! I am Lulu Ling. This is my marketing analytics project."
  },
  {
    "objectID": "Resume.html",
    "href": "Resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\nLulu Ling\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/Project1/index.html",
    "href": "blog/Project1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn oreder to explore if the price affects on chartibal giving behavior, Dean Karlan and John conducted a large scale experiment involving about 50,000 donors to a liberal nonprofit organization. The subjects were randomly assigned to two groups: a control group and an experimental group. The control group received a standard fundraising letter without any additional instructions, while the experimental group received a letter containing a matching grant.\nIn this experiment, people are further randomly assigned to different sub-treatment conditions, such as designs of matching ratio, matching amount cap and suggested donation amount. These details will be further described in the data description section. The group of treatment will receive letters included an additional paragraph inserted at the top of the second page that announced that a “concerned fellow member” will match their donation, and the reply card included in bold type the details of the match. For the control group, the reply card match language was replaced with a large logo of the organization.\nThis design allows researchers to not only estimate the average treatment effect, but also to further analyze the impact of different matching ratios, upper limits, and recommended amounts on donation decisions. In addition, the study also observed differential responses in red states and blue states, indicating that the political environment also affects the sensitivity of donation behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/Project1/index.html#section-1-data",
    "href": "blog/Project1/index.html#section-1-data",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data"
  },
  {
    "objectID": "blog/Project1/index.html#section-2-analysis",
    "href": "blog/Project1/index.html#section-2-analysis",
    "title": "This is Project 1",
    "section": "",
    "text": "I analyzed the data"
  },
  {
    "objectID": "blog/Project1/index.html#introduction",
    "href": "blog/Project1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn oreder to explore if the price affects on chartibal giving behavior, Dean Karlan and John conducted a large scale experiment involving about 50,000 donors to a liberal nonprofit organization. The subjects were randomly assigned to two groups: a control group and an experimental group. The control group received a standard fundraising letter without any additional instructions, while the experimental group received a letter containing a matching grant.\nIn this experiment, people are further randomly assigned to different sub-treatment conditions, such as designs of matching ratio, matching amount cap and suggested donation amount. These details will be further described in the data description section. The group of treatment will receive letters included an additional paragraph inserted at the top of the second page that announced that a “concerned fellow member” will match their donation, and the reply card included in bold type the details of the match. For the control group, the reply card match language was replaced with a large logo of the organization.\nThis design allows researchers to not only estimate the average treatment effect, but also to further analyze the impact of different matching ratios, upper limits, and recommended amounts on donation decisions. In addition, the study also observed differential responses in red states and blue states, indicating that the political environment also affects the sensitivity of donation behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/Project1/index.html#data",
    "href": "blog/Project1/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\nThis data comes from a large-scale natural field experiment conducted by a liberal nonprofit organization in the United States in 2005. The purpose of the study was to explore:\nDo different donation reminder designs affect people’s actual donation behavior?\nTreatment Conditions\n\nPaired ratios: $1:$1, $2:$1, $3:$1, control\nMaximum amount of matching: $25,000 / $50,000 / $100,000 / control\nAsk amount: based on 1.0 times, 1.25 times, or 1.5 times the donor’s highest past donation\n\nSample size and groups\n\nTotal sample size: 50,083 donors\nControl group: 16,687 people (33%)\nTreatment group: 33,396 people (67%)\n\nThe fundraising letter received contains instructions for matching donations and is randomly assigned to different matching ratio/maximum amount/suggested amount combinations\nLoading dataset\n\n\nCode\nimport pandas as pd\ndata = pd.read_stata('/home/jovyan/Desktop/UCSD/Spring/MGTA495/lulu_marketing_analytics/blog/Project1/karlan_list_2007.dta')\ndata.head()\n\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nI will select several non-significant variables to examine whether there are statistically significant differences (95% confidence level) between the experimental and control groups on these background characteristics. Each variable is analyzed using two methods: one is a t-test, and the other is to estimate the effect of treatment on the variable through simple linear regression, and compare whether the two methods give consistent results.\n\nVariable selections\n\nmrm2: Number of months since last donation\nltmedmra: Small prior donor: last gift was less than median $35\ncouple: Couple\n\nSplit the data into treatment and control groups\n\n\nCode\ntreatment_data = data[data['treatment'] == 1]\ncontrol_data = data[data['treatment'] == 0]\n\n\nT-test for mrm2, ltmedmra, couple\n\n\nCode\ncolumns = ['mrm2', 'ltmedmra', 'couple']\n\nt_stats = {}\n\nfor col in columns:\n\n    treatment_values = [x for x in treatment_data[col] if x == x]\n    control_values = [x for x in control_data[col] if x == x]\n\n    n1 = len(treatment_values)\n    n2 = len(control_values)\n\n    mean1 = sum(treatment_values) / n1\n    mean2 = sum(control_values) / n2\n\n    var1 = sum((x - mean1)**2 for x in treatment_values) / (n1 - 1)\n    var2 = sum((x - mean2)**2 for x in control_values) / (n2 - 1)\n\n    se = ((var1 / n1) + (var2 / n2)) ** 0.5\n\n    t_stat = (mean1 - mean2) / se\n\n    t_stats[col] = t_stat\n\n\nLinear regression for mrm2, ltmedmra, couple\n\n\nCode\nimport statsmodels.api as sm\n\nif 'intercept' not in data.columns:\n    data['intercept'] = 1\n\ncolumns_to_analyze = ['mrm2', 'ltmedmra', 'couple']\n\nregression_results = {}\n\nfor col in columns_to_analyze:\n    model = sm.OLS(data[col], data[['intercept', 'treatment']], missing='drop').fit()\n    t_stat = model.tvalues['treatment'].round(4)\n    p_value = model.pvalues['treatment'].round(4)\n    regression_results[col] = {'t-stat': t_stat, 'p-value': p_value}\n\n\nThe result of t-test and linear regression for mrm2, ltmedmra, couple\n\n\nCode\ncombined_t_stats_df = pd.DataFrame({\n    \"Variable\": list(t_stats.keys()) + list(regression_results.keys()),\n    \"T-statistic\": [round(value, 4) for value in t_stats.values()] + [result['t-stat'] for result in regression_results.values()],\n    \"Method\": [\"T-test\"] * len(t_stats) + [\"Regression\"] * len(regression_results)\n})\ncombined_t_stats_df\n\n\n\n\n\n\n\n\n\nVariable\nT-statistic\nMethod\n\n\n\n\n0\nmrm2\n0.1195\nT-test\n\n\n1\nltmedmra\n1.9099\nT-test\n\n\n2\ncouple\n-0.5823\nT-test\n\n\n3\nmrm2\n0.1195\nRegression\n\n\n4\nltmedmra\n1.9097\nRegression\n\n\n5\ncouple\n-0.5838\nRegression\n\n\n\n\n\n\n\nFirst, from the results of t-test:\n\nThe t-value of mrm2 was 0.1195, indicating that there was no significant difference between the treatment group and the control group.\nThe t-value of ltmedmra is 1.9099, which is close to the statistically significant level (usually the critical value is about 1.96), indicating that the difference between the treatment group and the control group in this variable is potentially significant.\nThe T value of couple was -0.5823, indicating that there was no significant difference in this variable between the two groups.\n\nNext, we further verified the responses of these variables to the treatment effects through linear regression. In regression analysis, we treat each variable as a dependent variable and the treatment variable (treatment) as an independent variable, and observe the estimated value of its coefficient and the T statistic:\n\nThe treatment coefficient t-value of mrm2 is still 0.1195, which is consistent with the T test, indicating that the treatment has no effect on this variable.\nThe regression t-value of ltmedmra is 1.9097, which is almost consistent with the T-test, further strengthening the inference that this variable may be affected by the treatment.\nThe regression t-value of couple is -0.5838, which is also close to the T-test, indicating that the treatment has no significant effect.\n\nThese results can be compared with Table 1 in the paper by Karlan and List. This table mainly presents the average values ​​and differences of various basic characteristics between the treatment group and the control group, with the aim of verifying whether the random assignment is successful. If there is no significant difference between the two groups on most variables, it can be reasonably inferred that the sample allocation is random, and subsequent causal inferences are more credible."
  },
  {
    "objectID": "blog/Project1/index.html#experimental-results",
    "href": "blog/Project1/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\nBar plot of the proportion of peole donated between treatment and controal group.\n\n\nCode\nimport matplotlib.pyplot as plt\n\ntreatment_prop = treatment_data['gave'].mean()\ncontrol_prop = control_data['gave'].mean()\n\nplt.bar(['Treatment', 'Control'], [treatment_prop, control_prop], color=['pink', 'lightblue'])\nplt.ylabel('Proportion of People Who Donated')\nplt.title('Proportion of Donors in Treatment and Control')\nplt.show()\n\n\n\n\n\n\n\n\n\nThe purpose of the following analysis is to compare the differences between the experimental group and the control group in terms of whether or not they donated. I will first use a t-test to preliminarily check whether there is a significant difference in the donation rates of the two groups, and then use a simple linear regression model with donation behavior as the dependent variable and the experimental treatment as the independent variable to further verify whether the results are consistent. These results will help us determine whether paired donation reminders can effectively enhance donation behavior and explore donors’ behavioral responses and potential psychological motivations. In addition, the data will be compared with Table 2A in the paper to confirm the consistency of the analysis direction with the original research.\nT test: compare whether there is a significant difference in the donation rate between the treatment and control groups\n\n\nCode\nfrom scipy import stats\ntreatment_gave = treatment_data['gave']\ncontrol_gave = control_data['gave']\n\nmean_treatment = treatment_gave.mean()\nmean_control = control_gave.mean()\n\nvar_treatment = treatment_gave.var(ddof=1)\nvar_control = control_gave.var(ddof=1)\n\nn_treatment = len(treatment_gave)\nn_control = len(control_gave)\n\nse = ((var_treatment / n_treatment) + (var_control / n_control)) ** 0.5\n\nt_stat_manual = (mean_treatment - mean_control) / se\n\ndf = ((var_treatment / n_treatment + var_control / n_control) ** 2) / \\\n    (((var_treatment / n_treatment) ** 2) / (n_treatment - 1) + ((var_control / n_control) ** 2) / (n_control - 1))\n\np_value_manual = 2 * (1 - stats.t.cdf(abs(t_stat_manual), df))\n\ngave_t_test_results = pd.DataFrame({\n    \"Metric\": [\"t-statistic\", \"p-value\"],\n    \"Value\": [t_stat_manual.round(4), p_value_manual.round(4)]\n})\n\ngave_t_test_results\n\n\n\n\n\n\n\n\n\nMetric\nValue\n\n\n\n\n0\nt-statistic\n3.2095\n\n\n1\np-value\n0.0013\n\n\n\n\n\n\n\nWe first conducted an independent sample t-test on the binary variable gave. The results showed that the t-value and the p-value indicating that the difference in donation rates between the treatment group and the control group was statistically significant at a 95% confidence level. This suggests that simply including the phrase “your donation will be matched” in your fundraising email can significantly increase donation rates.\nLinear regression: Using OLS to test the effect of treatment on donation behavior\n\n\nCode\ngave_model = sm.OLS(data['gave'], data[['intercept', 'treatment']], missing='drop').fit()\n\ngave_model_results = pd.DataFrame({\n    \"Metric\": [\"t-statistic\", \"p-value\"],\n    \"Value\": [gave_model.tvalues['treatment'].round(4), gave_model.pvalues['treatment'].round(4)]\n})\ngave_model_results\n\n\n\n\n\n\n\n\n\nMetric\nValue\n\n\n\n\n0\nt-statistic\n3.1014\n\n\n1\np-value\n0.0019\n\n\n\n\n\n\n\nTo verify this, we used simple linear regression with gave as the dependent variable and treatment as the independent variable. The results showed that the t-value and p-value were almost consistent with the t-test results, proving that the two methods are consistent when analyzing this type of binary outcome variable.\nThe proportion of respsonse rate in control gorup and treatment group\n\n\nCode\nproportions_df = pd.DataFrame({\n    \"Group\": [\"Control\", \"Treatment\"],\n    \"Proportion\": [control_prop, treatment_prop]\n})\nproportions_df\n\n\n\n\n\n\n\n\n\nGroup\nProportion\n\n\n\n\n0\nControl\n0.017858\n\n\n1\nTreatment\n0.022039\n\n\n\n\n\n\n\nThis result is also consistent with the data in Table 2A of the original text (1.8% in the control group and 2.2% in the experimental group). From a behavioral economics perspective, this stable difference may be because when people see the message that “your donation will be matched,” they feel that their donation is more valuable and more influential. This feeling will make them more willing to donate. It’s like people feel a sense of satisfaction when they donate, and the message of matching donations makes this satisfaction even stronger, thus increasing their willingness to act.\nOverall, this analysis supports the original authors’ conclusion: even without changing the amount, providing matching information can effectively increase the likelihood of donations, which has important implications for practical fundraising strategies.\nNext, I will conduct a Probit regression analysis to test the impact of “whether or not to receive a matching donation reminder” (treatment) on the outcome of “whether or not to donate” (gave, a variable of 0 or 1). This model can help you estimate the effect of the matching message on the probability of donating and can be used to verify whether your results are consistent with the analysis results in column 1 of Table 3 of the paper. This step is to confirm whether you have successfully reproduced the main conclusions of the original study.\nProbit Regression: Estimating the Effect of Pairing Prompts on the Probability of Donating\n\n\nCode\nprobit_model = sm.Probit(data['gave'], data[['intercept', 'treatment']])\nprobit_results = probit_model.fit()\n\ncoefficients = probit_results.params\nt_values = probit_results.tvalues\n\nprobit_summary_df = pd.DataFrame({\n    \"Variable\": coefficients.index,\n    \"Coefficient\": coefficients.values,\n    \"T-value\": t_values.values\n})\nprobit_summary_df.round(4)\n\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nT-value\n\n\n\n\n0\nintercept\n-2.1001\n-90.0728\n\n\n1\ntreatment\n0.0868\n3.1129\n\n\n\n\n\n\n\nMarginal effect analysis: explaining the actual effect of treatment on the probability of donating\n\n\nCode\nmarginal_effects = probit_results.get_margeff()\nmarginal_summary = marginal_effects.summary_frame()\n\nmarginal_summary = marginal_summary.reset_index().rename(columns={\n    'index': 'Variable',\n    'dy/dx': 'Marginal Effect (dy/dx)',\n    'Std. Err.': 'Std. Error',\n    'z': 'z',\n    'P&gt;|z|': 'P-value',\n    '[0.025': 'CI Lower',\n    '0.975]': 'CI Upper'\n})\n\nmarginal_summary.round(4)\n\n\n\n\n\n\n\n\n\nVariable\nMarginal Effect (dy/dx)\nStd. Error\nz\nPr(&gt;|z|)\nConf. Int. Low\nCont. Int. Hi.\n\n\n\n\n0\ntreatment\n0.0043\n0.0014\n3.1044\n0.0019\n0.0016\n0.007\n\n\n\n\n\n\n\nThe results are completely consistent with column 1 of Table 3 , successfully replicating the reported analysis. This means that the pairing prompt can significantly increase the probability of people donating, and even if the effect is small, it is statistically stable and significant. In the Probit model, the original coefficient cannot be directly interpreted as “how much the donation rate increased”, but it can be converted into a marginal effect. We can see from the Probit marginal effect model that the result is 0.0043, which corresponds exactly to 0.004 in the first column of Table 3.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nThrough t-test, we examine whether different matching ratios affect people’s donation behavior. Specifically, you will compare whether there are statistically significant differences in the donation rates of subjects under the 1:1, 2:1, and 3:1 pairing conditions. This will help you assess whether a higher or lower matching ratio has an additional impact on donation willingness.\nT-tests for match ratio effects on donation\n\n\nCode\nr1 = treatment_data[treatment_data['ratio'] == 1]\nr2 = treatment_data[treatment_data['ratio'] == 2]\nr3 = treatment_data[treatment_data['ratio'] == 3]\n\nmean_r1 = r1['gave'].mean()\nmean_r2 = r2['gave'].mean()\nmean_r3 = r3['gave'].mean()\n\nvar_r1 = r1['gave'].var(ddof=1)\nvar_r2 = r2['gave'].var(ddof=1)\nvar_r3 = r3['gave'].var(ddof=1)\n\nn_r1 = len(r1['gave'])\nn_r2 = len(r2['gave'])\nn_r3 = len(r3['gave'])\n\nse_1v2 = ((var_r1 / n_r1) + (var_r2 / n_r2)) ** 0.5\nse_2v3 = ((var_r2 / n_r2) + (var_r3 / n_r3)) ** 0.5\n\nt_stat_1v2 = (mean_r1 - mean_r2) / se_1v2\nt_stat_2v3 = (mean_r2 - mean_r3) / se_2v3\n\ndf_1v2 = ((var_r1 / n_r1 + var_r2 / n_r2) ** 2) / \\\n         (((var_r1 / n_r1) ** 2) / (n_r1 - 1) + ((var_r2 / n_r2) ** 2) / (n_r2 - 1))\ndf_2v3 = ((var_r2 / n_r2 + var_r3 / n_r3) ** 2) / \\\n         (((var_r2 / n_r2) ** 2) / (n_r2 - 1) + ((var_r3 / n_r3) ** 2) / (n_r3 - 1))\n\np_value_1v2 = 2 * (1 - stats.t.cdf(abs(t_stat_1v2), df_1v2))\np_value_2v3 = 2 * (1 - stats.t.cdf(abs(t_stat_2v3), df_2v3))\n\nt_test_results_df = pd.DataFrame({\n    \"Comparison\": [\"1:1 vs 2:1\", \"2:1 vs 3:1\"],\n    \"T-statistic\": [t_stat_1v2, t_stat_2v3],\n    \"P-value\": [p_value_1v2, p_value_2v3]\n})\n\nt_test_results_df\n\n\n\n\n\n\n\n\n\nComparison\nT-statistic\nP-value\n\n\n\n\n0\n1:1 vs 2:1\n-0.965049\n0.334531\n\n\n1\n2:1 vs 3:1\n-0.050116\n0.960031\n\n\n\n\n\n\n\nIn the paired donation prompt group, there were no significant behavioral differences between the different pairing ratios (1:1, 2:1, and 3:1).The t-value of the 1:1 and 2:1 groups is -0.965, and the p-value is 0.3345, indicating that we cannot reject the null hypothesis and there is no statistically significant difference in the donation rates between the two groups. The difference between the 2:1 and 3:1 groups is even smaller, with a t-value of only -0.0501 and a corresponding p-value of 0.96, indicating that there is no difference in donation behavior between the two groups.\nThe analysis results of the t-test support the author’s observations on page 8 of the paper. The authors note that while the pairing prompt itself increased donation rates, further increasing the pairing ratio (from 1:1 to 2:1 or 3:1) in the pairing prompt group did not lead to additional effects. The t-test you conducted also clearly reflects this point: the difference in donation rates between different matching ratios is not statistically significant, and the p-values ​​are all far higher than the traditional significance level, especially the difference between 2:1 and 3:1 is almost zero. This shows that in actual donation behavior, people are more sensitive to whether there is a match rather than the size of the matching ratio.\nRegression analysis was used to assess the effects of different pairing ratios (1:1, 2:1, 3:1) on donation behavior. The specific approach is to establish a linear regression model, with gave (whether to donate) as the dependent variable and three dummy variables representing the pairing ratios (ratio1, ratio2, ratio3) as independent variables. This allows us to simultaneously compare the effects of each pairing condition on the donation rate and analyze the regression coefficient of each variable and its statistical significance. Using this model, you will be able to determine whether a particular pairing ratio is particularly effective and whether the results are explanatory and stable.\nRegression analysis for match ratio effects\n\n\nCode\ndata['ratio1'] = (data['ratio'] == 1).astype(int)\n\nratio_model = sm.OLS(data['gave'], data[['intercept', 'ratio1', 'ratio2', 'ratio3']], missing='drop').fit()\n\n\nAccording to the regression results, we observed that different pairing ratios do have an impact on donation behavior, but the strength of the effect varies. The donation rate for ratio1 is about 0.29 percentage points higher, which is positive but only slightly statistically significant. The effects of the paired groups of ratio2 and ratio3 are more obvious, with the donation rates being approximately 0.48 and 0.49 percentage points higher than the benchmark group, respectively, and are significant at the 1% significance level.\nThis means that as long as there is matching information, even ratio 1 may increase people’s willingness to donate, and increasing the matching ratio to ratio 2 or ratio 3 will further strengthen this incentive. However, the effects of ratio2 and ratio3 are similar and almost the same, indicating that the marginal benefit of increasing the pairing ratio tends to be flat or saturated. This is consistent with the authors’ observation in the paper that higher pairing ratios do not necessarily produce additional significant behavioral changes.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\nResponse rate differences between different matching ratio\n\n\nCode\nresp_rate_1 = r1['gave'].mean()\nresp_rate_2 = r2['gave'].mean()\nresp_rate_3 = r3['gave'].mean()\n\ndiff_1v2 = resp_rate_2 - resp_rate_1\ndiff_2v3 = resp_rate_3 - resp_rate_2\n\nprint(f\"Response rate difference 1:1 vs 2:1: {diff_1v2:.4f}\")\nprint(f\"Response rate difference 2:1 vs 3:1: {diff_2v3:.4f}\")\n\n\nResponse rate difference 1:1 vs 2:1: 0.0019\nResponse rate difference 2:1 vs 3:1: 0.0001\n\n\nThe difference between the donation rates is very small, and further increasing the matching ratio, for example from ratio1 to ratio2 or ratio3, has very limited effect on the donation rate.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nI will use a t-test to exclude missing values ​​from the two groups and then compare whether there is a statistically significant difference in the average donation amounts of the two groups. This is a statistical method commonly used to compare whether two groups of means are different. A simple linear regression model was established, with the donation amount as the dependent variable and the treatment status as the explanatory variable, to examine whether there was a significant difference in the donation amount between the experimental group and the control group before controlling other variables.\nT-test for donation amount\n\n\nCode\ntreatment_amount = treatment_data['amount'].dropna()\ncontrol_amount = control_data['amount'].dropna()\n\nmean_treatment_amount = treatment_amount.mean()\nmean_control_amount = control_amount.mean()\n\nvar_treatment_amount = treatment_amount.var(ddof=1)\nvar_control_amount = control_amount.var(ddof=1)\n\nn_treatment_amount = len(treatment_amount)\nn_control_amount = len(control_amount)\n\nse_amount = ((var_treatment_amount / n_treatment_amount) + (var_control_amount / n_control_amount)) ** 0.5\n\nt_stat_amount_manual = (mean_treatment_amount - mean_control_amount) / se_amount\n\ndf_amount = ((var_treatment_amount / n_treatment_amount + var_control_amount / n_control_amount) ** 2) / \\\n    (((var_treatment_amount / n_treatment_amount) ** 2) / (n_treatment_amount - 1) + \n     ((var_control_amount / n_control_amount) ** 2) / (n_control_amount - 1))\n\np_value_amount_manual = 2 * (1 - stats.t.cdf(abs(t_stat_amount_manual), df_amount))\n\nt_test_amount_manual_results = pd.DataFrame({\n    \"Metric\": [\"t-statistic\", \"p-value\"],\n    \"Value\": [t_stat_amount_manual.round(4), p_value_amount_manual.round(4)]\n})\n\nt_test_amount_manual_results\n\n\n\n\n\n\n\n\n\nMetric\nValue\n\n\n\n\n0\nt-statistic\n1.9182\n\n\n1\np-value\n0.0551\n\n\n\n\n\n\n\nBivariate linear regression for donation amount\n\n\nCode\namount_model = sm.OLS(data['amount'], data[['intercept', 'treatment']], missing='drop').fit()\n\namount_model_results = pd.DataFrame({\n    \"Metric\": [\"t-statistic\", \"p-value\"], \n    \"Value\": [amount_model.tvalues['treatment'].round(4), amount_model.pvalues['treatment'].round(4)]\n})\namount_model_results\n\n\n\n\n\n\n\n\n\nMetric\nValue\n\n\n\n\n0\nt-statistic\n1.8605\n\n\n1\np-value\n0.0628\n\n\n\n\n\n\n\nWhen we analyzed the donation amount, both the independent sample t-test and the bivariate linear regression showed that the average donation amount of the treatment group was slightly higher than that of the control group, but the difference was only marginally significant. The p-value of the t-test is 0.0551, and the p-value of the regression is 0.063, both slightly higher than the traditional 5% significance level.\nOverall, the matching prompt has a clear impact on whether to donate, while the impact of amount is weaker. From a behavioral perspective, the matching message is more like a “motivation switch” that prompts people to take action rather than a reinforcement tool that influences the amount of donations. This also means that in terms of fundraising strategy, matching donations are more suitable as an incentive to guide donation behavior rather than a means to increase the single amount.\nNext, we will conduct a regression analysis on those who actually donated to assess whether the paired prompt (treatment) affects the amount they donated. First, the program will filter out all observations with donation amounts greater than 0 from the data, and then build a simple linear regression model with the donation amount as the dependent variable and whether or not the matching prompt was received as the independent variable.\nConditional donation amount regression analysis: evaluating the impact and explanatory power of matching prompts only for actual donors\n\n\nCode\ndonors = data[data['amount'] &gt; 0]\n\ndonors_model = sm.OLS(donors['amount'], donors[['intercept', 'treatment']], missing='drop').fit()\n\ntreatment_coef = donors_model.params['treatment']\n\ntreatment_coef_df = pd.DataFrame({\n    \"Metric\": [\"Treatment Coefficient\"],\n    \"Value\": [treatment_coef.round(4)]\n})\n\ntreatment_coef_df\n\n\n\n\n\n\n\n\n\nMetric\nValue\n\n\n\n\n0\nTreatment Coefficient\n-1.6684\n\n\n\n\n\n\n\nIn this regression analysis of those who have already donated, the treatment coefficient is -1.6684, it means that the average donation amount of the treatment group is about 1.67 yuan lower than that of the control group., however, this result is not statistically significant because the p-value is only 0.561, indicating that the matching prompt has no stable effect on the amount donated by those who have already decided to donate. It should be noted that this regression result cannot be interpreted as a causal effect of treatment on the amount of donations, because the analysis is limited to people who actually donated. This is a conditional subsample and not a random assignment, so there is a risk of selection bias. Taken together, our findings suggest that matching donation prompts are more likely to influence the behavior of whether to donate rather than the amount of donation.\nCompare the distribution of donation amounts among those who actually donated in the treatment group and the control group. First, the program will screen out the subjects in the two groups whose donation amount is greater than 0, and then calculate the average donation amount of each group.\nCompare the distribution of donations between treatment and control groups (limited to donors)\n\n\nCode\ntreatment_donors = treatment_data[treatment_data['amount'] &gt; 0]\ncontrol_donors = control_data[control_data['amount'] &gt; 0]\n\ntreatment_avg = treatment_donors['amount'].mean()\ncontrol_avg = control_donors['amount'].mean()\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n\naxes[0].hist(treatment_donors['amount'], bins=30, color='skyblue', alpha=0.7)\naxes[0].axvline(treatment_avg, color='red', linestyle='--', label=f'Avg: {treatment_avg:.2f}')\naxes[0].set_title('Treatment Group: Donation Amounts')\naxes[0].set_xlabel('Donation Amount')\naxes[0].set_ylabel('Frequency')\naxes[0].legend()\n\naxes[1].hist(control_donors['amount'], bins=30, color='pink', alpha=0.7)\naxes[1].axvline(control_avg, color='red', linestyle='--', label=f'Avg: {control_avg:.2f}')\naxes[1].set_title('Control Group: Donation Amounts')\naxes[1].set_xlabel('Donation Amount')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "blog/Project1/index.html#simulation-experiment",
    "href": "blog/Project1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nThe Law of Large Numbers is demonstrated through a simulation. 100,000 records are simulated from the control group (donation rate 1.8%) and 10,000 records are simulated from the treatment group (donation rate 2.2%). Then, the same number of samples are randomly selected from the control data to pair with the treatment data. The difference between the treatment and control donation results is calculated for each\nSimulation of the Law of Large Numbers: Cumulative Average Difference in Donation Rates\n\n\nCode\nimport numpy as np\n#calculation\nnp.random.seed(42)\ncontrol_draws = np.random.binomial(n=1, p=0.018, size=100000)\ntreatment_draws = np.random.binomial(n=1, p=0.022, size=10000)\ncontrol_sample = np.random.choice(control_draws, size=10000, replace=False)\ndiff = treatment_draws - control_sample\ncumulative_avg = np.cumsum(diff) / np.arange(1, len(diff) + 1)\n#plot\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg, label=\"Cumulative mean difference\")\nplt.axhline(y=0.004, color='red', linestyle='--', label=\"Theoretical mean difference = 0.004\")\nplt.title(\"Simulation: Cumulative Average Difference in Donation Rates)\")\nplt.xlabel(\"Sample Size\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nThis graph shows the difference in donation rates between the treatment group and the control group, calculated through simulations, as the number of samples increases. As can be seen from the figure, although the difference fluctuates greatly when the number of samples is small, as the number of samples gradually increases, the cumulative average curve steadily approaches the theoretical true difference value of 0.004.\nThis is a typical manifestation of the Law of Large Numbers: when we observe enough samples, the mean of the samples will approach the true mean of the population. This also means that the difference in donation rates observed in the original experiment (the slightly higher donation rate in the treatment group than in the control group) was not caused by random errors, but was a stable and reproducible result.\nTherefore, we can reasonably say that the simulation results in this figure verify the stability and credibility of the treatment effect and provide strong visual evidence to support that the observations in the experiment are reliable.\n\n\nCentral Limit Theorem\nNext, we will show the distribution of the average difference in donation rates between the treatment group and the control group under different sample sizes (50, 200, 500, 1000). For each sample size, 1000 random draws were made, taking an equal number of samples from the simulated distributions for both treatment and control, calculating the mean differences between the two groups, and plotting these differences in a histogram.\n\n\nCode\nimport numpy as np\n\ncontrol_draws = np.random.binomial(1, 0.018, 100000)\ntreatment_draws = np.random.binomial(1, 0.022, 10000)\nsample_sizes = [50, 200, 500, 1000]\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\naxes = axes.flatten()\n\nfor i, sample_size in enumerate(sample_sizes):\n    avg_differences = []\n\n    for _ in range(1000):\n        treatment_sample = np.random.choice(treatment_draws, size=sample_size, replace=True)\n        control_sample = np.random.choice(control_draws, size=sample_size, replace=True)\n        avg_differences.append(np.mean(treatment_sample - control_sample))\n\n    axes[i].hist(avg_differences, bins=30, color='pink', edgecolor='black', alpha=0.7)\n    axes[i].axvline(0, color='red', linestyle='--', label='Zero')\n    axes[i].set_title(f'Sample Size: {sample_size}')\n    axes[i].set_xlabel('Average Difference')\n    axes[i].set_ylabel('Frequency')\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nThese four histograms show the simulated distribution changes of the difference in donation rates between the treatment group and the control group under different sample sizes (50, 200, 500, 1000). When the sample size is small, the distribution is more dispersed, and 0 almost falls in the center, which means that it is impossible to determine whether the treatment effect is significant. However, as the number of samples increases, the distribution begins to become concentrated and biased toward positive differences, especially when the number of samples reaches 500 or 1000, when 0 is clearly off the center and falls in the left tail of the distribution. This means that when the sample size is sufficient, the treatment group does show a stable and positive effect, and the average donation rate is higher than that of the control group. This difference is unlikely to be caused by random errors. Overall, this set of charts reinforces a basic principle in statistical inference: the larger the sample size, the more stable the results and the more reliably they reveal true behavioral differences."
  },
  {
    "objectID": "blog/Project1/hw1_questions.html",
    "href": "blog/Project1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/Project1/hw1_questions.html#introduction",
    "href": "blog/Project1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/Project1/hw1_questions.html#data",
    "href": "blog/Project1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "blog/Project1/hw1_questions.html#experimental-results",
    "href": "blog/Project1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "blog/Project1/hw1_questions.html#simulation-experiment",
    "href": "blog/Project1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "blog/Project1/project1.html",
    "href": "blog/Project1/project1.html",
    "title": "Lulu's Marketing Analytics Project",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport os\n\n\ndata = pd.read_stata('/home/jovyan/Desktop/UCSD/Spring/MGTA495/lulu_marketing_analytics/blog/Project1/karlan_list_2007.dta')\ndata\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.688262\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\n0.900000\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.917206\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.530023\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\n\n\n\n\n50083 rows × 51 columns\n\n\n\n\ndata.to_excel('output_data.xlsx', index=False)\n\n\ntreatment_data = data[data['treatment'] == 1]\n\n\ncontrol_data = data[data['treatment'] == 0]\n\n\nfrom scipy.stats import ttest_ind\n\n# T-test for mrm2\ntreatment_mrm2 = treatment_data['mrm2'].dropna()\ncontrol_mrm2 = control_data['mrm2'].dropna()\nt_stat, p_value = ttest_ind(treatment_mrm2, control_mrm2, equal_var=False)\nprint(f\"T-test for mrm2: t-statistic = {t_stat.round(4)}, p-value = {p_value.round(4)}\")\n\nT-test for mrm2: t-statistic = 0.1195, p-value = 0.9049\n\n\n\n# 去除缺漏值\ntreatment_mrm2 = [x for x in treatment_data['mrm2'] if x == x]\ncontrol_mrm2 = [x for x in control_data['mrm2'] if x == x]\n\n# 計算樣本數\nn1 = len(treatment_mrm2)\nn2 = len(control_mrm2)\n\n# 計算平均\nmean1 = sum(treatment_mrm2) / n1\nmean2 = sum(control_mrm2) / n2\n\n# 計算變異數（無偏估計，分母用 n-1）\nvar1 = sum((x - mean1)**2 for x in treatment_mrm2) / (n1 - 1)\nvar2 = sum((x - mean2)**2 for x in control_mrm2) / (n2 - 1)\n\n# 計算標準誤\nse = ((var1 / n1) + (var2 / n2)) ** 0.5\n\n# 計算 t 統計量\nt_stat = (mean1 - mean2) / se\n\nprint(f\"T-test (by formula) for mrm2: t-statistic = {round(t_stat, 4)}\")\n\nT-test (by formula) for mrm2: t-statistic = 0.1195\n\n\n\nimport statsmodels.api as sm\n\n# Linear regression for mrm2\ndata['intercept'] = 1 \nmodel = sm.OLS(data['mrm2'], data[['intercept', 'treatment']], missing='drop').fit()\nprint(model.summary())\n# Extract the t-statistic for the 'treatment' coefficient from the regression model\nregression_t_stat = model.tvalues['treatment'].round(4)\nprint(f\"Regression model t-statistic: {regression_t_stat}\")\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):              0.905\nTime:                        16:22:47   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nRegression model t-statistic: 0.1195\n\n\n\nimport matplotlib.pyplot as plt\n\ntreatment_proportion = treatment_data['gave'].mean()\ncontrol_proportion = control_data['gave'].mean()\n\nplt.bar(['Treatment', 'Control'], [treatment_proportion, control_proportion], color=['pink', 'lightblue'])\nplt.ylabel('Proportion of People Who Donated')\nplt.title('Proportion of Donors by Group')\nplt.show()\n\n\n\n\n\n\n\n\n\n# T-test for the binary outcome 'gave'\ntreatment_gave = treatment_data['gave']\ncontrol_gave = control_data['gave']\nt_stat_gave, p_value_gave = ttest_ind(treatment_gave, control_gave, equal_var=False)\nprint(f\"T-test for 'gave': t-statistic = {t_stat_gave.round(4)}, p-value = {p_value_gave.round(4)}\")\n\n# Bivariate linear regression for 'gave'\ngave_model = sm.OLS(data['gave'], data[['intercept', 'treatment']], missing='drop').fit()\nprint(gave_model.summary())\nprint(f\"Linear regression for 'gave': t-statistic = {gave_model.tvalues['treatment'].round(4)}\")\n\nT-test for 'gave': t-statistic = 3.2095, p-value = 0.0013\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):            0.00193\nTime:                        16:22:47   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nLinear regression for 'gave': t-statistic = 3.1014\n\n\n\nprint(f\"Control Proportion: {control_proportion:.3f}\")\nprint(f\"Treatment Proportion: {treatment_proportion:.3f}\")\n\nControl Proportion: 0.018\nTreatment Proportion: 0.022\n\n\n\n# Probit regression for charitable donation\nprobit_model = sm.Probit(data['gave'], data[['intercept', 'treatment']])\nprobit_results = probit_model.fit()\nprint(probit_results.summary())\n\n# 邊際效應估計\nmarginal_effects = probit_results.get_margeff()\nprint(marginal_effects.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Tue, 22 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        00:08:21   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment      0.0043      0.001      3.104      0.002       0.002       0.007\n==============================================================================\n\n\n\nfrom scipy.stats import ttest_ind\n\n# Task 1: T-tests for match ratio effects on donation likelihood\n\n# Filter data for each match ratio\nratio1_data = treatment_data[treatment_data['ratio'] == 1]\nratio2_data = treatment_data[treatment_data['ratio'] == 2]\nratio3_data = treatment_data[treatment_data['ratio'] == 3]\n\n# Perform t-tests\nt_stat_1v2, p_value_1v2 = ttest_ind(ratio1_data['gave'], ratio2_data['gave'], equal_var=False)\nt_stat_2v3, p_value_2v3 = ttest_ind(ratio2_data['gave'], ratio3_data['gave'], equal_var=False)\n\nprint(f\"T-test 1:1 vs 2:1 - t-statistic: {t_stat_1v2:.4f}, p-value: {p_value_1v2:.4f}\")\nprint(f\"T-test 2:1 vs 3:1 - t-statistic: {t_stat_2v3:.4f}, p-value: {p_value_2v3:.4f}\")\n\n\n\n\nT-test 1:1 vs 2:1 - t-statistic: -0.9650, p-value: 0.3345\nT-test 2:1 vs 3:1 - t-statistic: -0.0501, p-value: 0.9600\n\n\n\ndata['ratio1'] = (data['ratio'] == 1).astype(int)\n\nratio_model = sm.OLS(data['gave'], data[['intercept', 'ratio1', 'ratio2', 'ratio3']], missing='drop').fit()\nprint(ratio_model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.665\nDate:                Tue, 22 Apr 2025   Prob (F-statistic):             0.0118\nTime:                        11:02:58   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.322e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.0179      0.001     16.225      0.000       0.016       0.020\nratio1         0.0029      0.002      1.661      0.097      -0.001       0.006\nratio2         0.0048      0.002      2.744      0.006       0.001       0.008\nratio3         0.0049      0.002      2.802      0.005       0.001       0.008\n==============================================================================\nOmnibus:                    59812.754   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4316693.217\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.438   Cond. No.                         4.26\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n# Task 3: Response rate differences\n# Direct calculation from data\nresponse_rate_1 = ratio1_data['gave'].mean()\nresponse_rate_2 = ratio2_data['gave'].mean()\nresponse_rate_3 = ratio3_data['gave'].mean()\n\ndiff_1v2 = response_rate_2 - response_rate_1\ndiff_2v3 = response_rate_3 - response_rate_2\n\nprint(f\"Response rate difference 1:1 vs 2:1: {diff_1v2:.4f}\")\nprint(f\"Response rate difference 2:1 vs 3:1: {diff_2v3:.4f}\")\n\nResponse rate difference 1:1 vs 2:1: 0.0019\nResponse rate difference 2:1 vs 3:1: 0.0001\n\n\n\n# Differences from regression coefficients\ncoef_diff_1v2 = ratio_model.params['ratio2'] - ratio_model.params['ratio1']\ncoef_diff_2v3 = ratio_model.params['ratio3'] - ratio_model.params['ratio2']\n\nprint(f\"Coefficient difference 1:1 vs 2:1: {coef_diff_1v2:.4f}\")\nprint(f\"Coefficient difference 2:1 vs 3:1: {coef_diff_2v3:.4f}\")\n\nCoefficient difference 1:1 vs 2:1: 0.0019\nCoefficient difference 2:1 vs 3:1: 0.0001\n\n\n\n# T-test for donation amount\ntreatment_amount = treatment_data['amount'].dropna()\ncontrol_amount = control_data['amount'].dropna()\nt_stat_amount, p_value_amount = ttest_ind(treatment_amount, control_amount, equal_var=False)\nprint(f\"T-test for donation amount: t-statistic = {t_stat_amount:.4f}, p-value = {p_value_amount:.4f}\")\n\n# Bivariate linear regression for donation amount\namount_model = sm.OLS(data['amount'], data[['intercept', 'treatment']], missing='drop').fit()\nprint(amount_model.summary())\nprint(f\"Linear regression for donation amount: t-statistic = {amount_model.tvalues['treatment']:.4f}, p-value = {amount_model.pvalues['treatment']:.4f}\")\n\nT-test for donation amount: t-statistic = 1.9183, p-value = 0.0551\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):             0.0628\nTime:                        16:22:48   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nLinear regression for donation amount: t-statistic = 1.8605, p-value = 0.0628\n\n\n\n# Filter data to include only those who made a donation\ndonors_data = data[data['amount'] &gt; 0]\n\n# Regression analysis for donation amount conditional on donating\ndonors_model = sm.OLS(donors_data['amount'], donors_data[['intercept', 'treatment']], missing='drop').fit()\nprint(donors_model.summary())\n\n# Interpretation of the treatment coefficient\ntreatment_coef = donors_model.params['treatment']\nprint(f\"Treatment coefficient: {treatment_coef:.4f}\")\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Mon, 21 Apr 2025   Prob (F-statistic):              0.561\nTime:                        16:22:48   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nTreatment coefficient: -1.6684\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 模擬參數\nn_control = 100000\nn_treatment = 10000\np_control = 0.018\np_treatment = 0.022\n\n# 隨機抽樣\nnp.random.seed(42)\ncontrol_draws = np.random.binomial(n=1, p=p_control, size=n_control)\ntreatment_draws = np.random.binomial(n=1, p=p_treatment, size=n_treatment)\n\n# 從控制組中隨機抽出與 treatment 組一樣多的樣本\ncontrol_sample = np.random.choice(control_draws, size=n_treatment, replace=False)\n\n# 計算逐筆差異\ndifferences = treatment_draws - control_sample\n\n# 計算累積平均\ncumulative_avg = np.cumsum(differences) / np.arange(1, len(differences) + 1)\n\n# 繪製圖形\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg, label=\"Cumulative mean difference\")\nplt.axhline(y=0.004, color='red', linestyle='--', label=\"Theoretical mean difference = 0.004\")\nplt.title(\"Simulation: Cumulative Average Difference in Donation Rates)\")\nplt.xlabel(\"Sample Size\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Filter data for donors only\ntreatment_donors = treatment_data[treatment_data['amount'] &gt; 0]\ncontrol_donors = control_data[control_data['amount'] &gt; 0]\n\n# Calculate sample averages\ntreatment_avg = treatment_donors['amount'].mean()\ncontrol_avg = control_donors['amount'].mean()\n\n# Plot histograms\nfig, axes = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n\n# Treatment group histogram\naxes[0].hist(treatment_donors['amount'], bins=30, color='skyblue', alpha=0.7)\naxes[0].axvline(treatment_avg, color='red', linestyle='--', label=f'Avg: {treatment_avg:.2f}')\naxes[0].set_title('Treatment Group: Donation Amounts')\naxes[0].set_xlabel('Donation Amount')\naxes[0].set_ylabel('Frequency')\naxes[0].legend()\n\n# Control group histogram\naxes[1].hist(control_donors['amount'], bins=30, color='pink', alpha=0.7)\naxes[1].axvline(control_avg, color='red', linestyle='--', label=f'Avg: {control_avg:.2f}')\naxes[1].set_title('Control Group: Donation Amounts')\naxes[1].set_xlabel('Donation Amount')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n# Define sample sizes\nsample_sizes = [50, 200, 500, 1000]\n\n# Initialize a figure for subplots\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\naxes = axes.flatten()\n\n# Loop through each sample size\nfor i, sample_size in enumerate(sample_sizes):\n    avg_differences = []\n    \n    # Simulate 1000 averages\n    for _ in range(1000):\n        treatment_sample = np.random.choice(treatment_draws, size=sample_size, replace=True)\n        control_sample = np.random.choice(control_draws, size=sample_size, replace=True)\n        avg_differences.append(np.mean(treatment_sample - control_sample))\n    \n    # Plot histogram\n    axes[i].hist(avg_differences, bins=30, color='pink', edgecolor='black', alpha=0.7)\n    axes[i].axvline(0, color='red', linestyle='--', label='Zero')\n    axes[i].set_title(f'Sample Size: {sample_size}')\n    axes[i].set_xlabel('Average Difference')\n    axes[i].set_ylabel('Frequency')\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "blog/Project2/project1.html",
    "href": "blog/Project2/project1.html",
    "title": "Lulu's Marketing Analytics Project",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport os\n\n\ndata = pd.read_stata('/home/jovyan/Desktop/UCSD/Spring/MGTA495/lulu_marketing_analytics/blog/Project1/karlan_list_2007.dta')\ndata\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.688262\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\n0.900000\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.917206\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.530023\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\n\n\n\n\n50083 rows × 51 columns\n\n\n\n\ndata.to_excel('output_data.xlsx', index=False)\n\n\ntreatment_data = data[data['treatment'] == 1]\n\n\ncontrol_data = data[data['treatment'] == 0]\n\n\n# Define the columns to calculate t-statistics for\ncolumns = ['mrm2', 'ltmedmra', 'couple']\n\n# Initialize a dictionary to store t-statistics\nt_stats = {}\n\n# Loop through each column\nfor col in columns:\n    # Filter non-NaN values for treatment and control groups\n    treatment_values = [x for x in treatment_data[col] if x == x]\n    control_values = [x for x in control_data[col] if x == x]\n\n    # Calculate sample sizes\n    n1 = len(treatment_values)\n    n2 = len(control_values)\n\n    # Calculate means\n    mean1 = sum(treatment_values) / n1\n    mean2 = sum(control_values) / n2\n\n    # Calculate variances\n    var1 = sum((x - mean1)**2 for x in treatment_values) / (n1 - 1)\n    var2 = sum((x - mean2)**2 for x in control_values) / (n2 - 1)\n\n    # Calculate standard error\n    se = ((var1 / n1) + (var2 / n2)) ** 0.5\n\n    # Calculate t-statistic\n    t_stat = (mean1 - mean2) / se\n\n    # Store the t-statistic in the dictionary\n    t_stats[col] = t_stat\n\n\nimport statsmodels.api as sm\n\n# 確保資料中有 'intercept' 欄位\nif 'intercept' not in data.columns:\n    data['intercept'] = 1\n\n# 定義要計算 t-stat 的欄位\ncolumns_to_analyze = ['mrm2', 'ltmedmra', 'couple']\n\n# 初始化一個字典來儲存結果\nregression_results = {}\n\n# 迴圈計算每個欄位的 t-stat 和 p-value\nfor col in columns_to_analyze:\n    model = sm.OLS(data[col], data[['intercept', 'treatment']], missing='drop').fit()\n    t_stat = model.tvalues['treatment'].round(4)\n    p_value = model.pvalues['treatment'].round(4)\n    regression_results[col] = {'t-stat': t_stat, 'p-value': p_value}\n\n\n# Combine T-test and Regression results into a single DataFrame\ncombined_t_stats_df = pd.DataFrame({\n    \"Variable\": list(t_stats.keys()) + list(regression_results.keys()),\n    \"T-statistic\": [round(value, 4) for value in t_stats.values()] + [result['t-stat'] for result in regression_results.values()],\n    \"Method\": [\"T-test\"] * len(t_stats) + [\"Regression\"] * len(regression_results)\n})\n\nprint(combined_t_stats_df)\n\n   Variable  T-statistic      Method\n0      mrm2       0.1195      T-test\n1  ltmedmra       1.9099      T-test\n2    couple      -0.5823      T-test\n3      mrm2       0.1195  Regression\n4  ltmedmra       1.9097  Regression\n5    couple      -0.5838  Regression\n\n\n\nimport matplotlib.pyplot as plt\n\ntreatment_proportion = treatment_data['gave'].mean()\ncontrol_proportion = control_data['gave'].mean()\n\nplt.bar(['Treatment', 'Control'], [treatment_proportion, control_proportion], color=['pink', 'lightblue'])\nplt.ylabel('Proportion of People Who Donated')\nplt.title('Proportion of Donors by Group')\nplt.show()\n\n\n\n\n\n\n\n\n\ntreatment_gave = treatment_data['gave']\ncontrol_gave = control_data['gave']\n\n\n# T-test for the binary outcome 'gave'\nfrom scipy.stats import ttest_ind\nt_stat_gave, p_value_gave = ttest_ind(treatment_gave, control_gave, equal_var=False)\nprint(f\"T-test for 'gave': t-statistic = {t_stat_gave.round(4)}, p-value = {p_value_gave.round(4)}\")\n\n# Bivariate linear regression for 'gave'\ngave_model = sm.OLS(data['gave'], data[['intercept', 'treatment']], missing='drop').fit()\nprint(gave_model.summary())\nprint(f\"Linear regression for 'gave': t-statistic = {gave_model.tvalues['treatment'].round(4)}\")\n\nT-test for 'gave': t-statistic = 3.2095, p-value = 0.0013\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):            0.00193\nTime:                        15:01:13   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nLinear regression for 'gave': t-statistic = 3.1014\n\n\n\nfrom scipy import stats\n\n# Calculate means\nmean_treatment = treatment_gave.mean()\nmean_control = control_gave.mean()\n\n# Calculate variances\nvar_treatment = treatment_gave.var(ddof=1)\nvar_control = control_gave.var(ddof=1)\n\n# Calculate sample sizes\nn_treatment = len(treatment_gave)\nn_control = len(control_gave)\n\n# Calculate the pooled standard error\nse = ((var_treatment / n_treatment) + (var_control / n_control)) ** 0.5\n\n# Calculate the t-statistic\nt_stat_manual = (mean_treatment - mean_control) / se\n\n# Degrees of freedom for unequal variances (Welch's t-test)\ndf = ((var_treatment / n_treatment + var_control / n_control) ** 2) / \\\n    (((var_treatment / n_treatment) ** 2) / (n_treatment - 1) + ((var_control / n_control) ** 2) / (n_control - 1))\n\n# Calculate the p-value (two-tailed)\np_value_manual = 2 * (1 - stats.t.cdf(abs(t_stat_manual), df))\n\nprint(f\"t-statistic = {t_stat_manual.round(4)}, p-value = {p_value_manual.round(4)}\")\n\nt-statistic = 3.2095, p-value = 0.0013\n\n\n\n# Create a DataFrame to store the t-statistic and p-value\ngave_t_test_results = pd.DataFrame({\n    \"Metric\": [\"t-statistic\", \"p-value\"],\n    \"Value\": [t_stat_manual.round(4), p_value_manual.round(4)]\n})\n\nprint(gave_t_test_results)\n\n        Metric   Value\n0  t-statistic  3.2095\n1      p-value  0.0013\n\n\n\ngave_model_results = pd.DataFrame({\n    \"Metric\": [\"t-statistic\", \"p-value\"],\n    \"Value\": [gave_model.tvalues['treatment'].round(4), gave_model.pvalues['treatment'].round(4)]\n})\n\nprint(gave_model_results)\n\n\nproportions_df = pd.DataFrame({\n    \"Group\": [\"Control\", \"Treatment\"],\n    \"Proportion\": [control_proportion, treatment_proportion]\n})\n\nprint(proportions_df)\n\n\nprint(f\"Control Proportion: {control_proportion:.3f}\")\nprint(f\"Treatment Proportion: {treatment_proportion:.3f}\")\n\n\n# Probit regression for charitable donation\nprobit_model = sm.Probit(data['gave'], data[['intercept', 'treatment']])\nprobit_results = probit_model.fit()\nprint(probit_results.summary())\n\n# 邊際效應估計\nmarginal_effects = probit_results.get_margeff()\nprint(marginal_effects.summary())\n\n\nfrom scipy.stats import ttest_ind\n\n# Task 1: T-tests for match ratio effects on donation likelihood\n\n# Filter data for each match ratio\nratio1_data = treatment_data[treatment_data['ratio'] == 1]\nratio2_data = treatment_data[treatment_data['ratio'] == 2]\nratio3_data = treatment_data[treatment_data['ratio'] == 3]\n\n# Perform t-tests\nt_stat_1v2, p_value_1v2 = ttest_ind(ratio1_data['gave'], ratio2_data['gave'], equal_var=False)\nt_stat_2v3, p_value_2v3 = ttest_ind(ratio2_data['gave'], ratio3_data['gave'], equal_var=False)\n\nprint(f\"T-test 1:1 vs 2:1 - t-statistic: {t_stat_1v2:.4f}, p-value: {p_value_1v2:.4f}\")\nprint(f\"T-test 2:1 vs 3:1 - t-statistic: {t_stat_2v3:.4f}, p-value: {p_value_2v3:.4f}\")\n\n\n\n\n\ndata['ratio1'] = (data['ratio'] == 1).astype(int)\n\nratio_model = sm.OLS(data['gave'], data[['intercept', 'ratio1', 'ratio2', 'ratio3']], missing='drop').fit()\nprint(ratio_model.summary())\n\n\n\n# Task 3: Response rate differences\n# Direct calculation from data\nresponse_rate_1 = ratio1_data['gave'].mean()\nresponse_rate_2 = ratio2_data['gave'].mean()\nresponse_rate_3 = ratio3_data['gave'].mean()\n\ndiff_1v2 = response_rate_2 - response_rate_1\ndiff_2v3 = response_rate_3 - response_rate_2\n\nprint(f\"Response rate difference 1:1 vs 2:1: {diff_1v2:.4f}\")\nprint(f\"Response rate difference 2:1 vs 3:1: {diff_2v3:.4f}\")\n\n\n# Differences from regression coefficients\ncoef_diff_1v2 = ratio_model.params['ratio2'] - ratio_model.params['ratio1']\ncoef_diff_2v3 = ratio_model.params['ratio3'] - ratio_model.params['ratio2']\n\nprint(f\"Coefficient difference 1:1 vs 2:1: {coef_diff_1v2:.4f}\")\nprint(f\"Coefficient difference 2:1 vs 3:1: {coef_diff_2v3:.4f}\")\n\n\n# T-test for donation amount\ntreatment_amount = treatment_data['amount'].dropna()\ncontrol_amount = control_data['amount'].dropna()\nt_stat_amount, p_value_amount = ttest_ind(treatment_amount, control_amount, equal_var=False)\nprint(f\"T-test for donation amount: t-statistic = {t_stat_amount:.4f}, p-value = {p_value_amount:.4f}\")\n\n# Bivariate linear regression for donation amount\namount_model = sm.OLS(data['amount'], data[['intercept', 'treatment']], missing='drop').fit()\nprint(amount_model.summary())\nprint(f\"Linear regression for donation amount: t-statistic = {amount_model.tvalues['treatment']:.4f}, p-value = {amount_model.pvalues['treatment']:.4f}\")\n\n\n# Filter data to include only those who made a donation\ndonors_data = data[data['amount'] &gt; 0]\n\n# Regression analysis for donation amount conditional on donating\ndonors_model = sm.OLS(donors_data['amount'], donors_data[['intercept', 'treatment']], missing='drop').fit()\nprint(donors_model.summary())\n\n# Interpretation of the treatment coefficient\ntreatment_coef = donors_model.params['treatment']\nprint(f\"Treatment coefficient: {treatment_coef:.4f}\")\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 模擬參數\nn_control = 100000\nn_treatment = 10000\np_control = 0.018\np_treatment = 0.022\n\n# 隨機抽樣\nnp.random.seed(42)\ncontrol_draws = np.random.binomial(n=1, p=p_control, size=n_control)\ntreatment_draws = np.random.binomial(n=1, p=p_treatment, size=n_treatment)\n\n# 從控制組中隨機抽出與 treatment 組一樣多的樣本\ncontrol_sample = np.random.choice(control_draws, size=n_treatment, replace=False)\n\n# 計算逐筆差異\ndifferences = treatment_draws - control_sample\n\n# 計算累積平均\ncumulative_avg = np.cumsum(differences) / np.arange(1, len(differences) + 1)\n\n# 繪製圖形\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg, label=\"Cumulative mean difference\")\nplt.axhline(y=0.004, color='red', linestyle='--', label=\"Theoretical mean difference = 0.004\")\nplt.title(\"Simulation: Cumulative Average Difference in Donation Rates)\")\nplt.xlabel(\"Sample Size\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n# Filter data for donors only\ntreatment_donors = treatment_data[treatment_data['amount'] &gt; 0]\ncontrol_donors = control_data[control_data['amount'] &gt; 0]\n\n# Calculate sample averages\ntreatment_avg = treatment_donors['amount'].mean()\ncontrol_avg = control_donors['amount'].mean()\n\n# Plot histograms\nfig, axes = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n\n# Treatment group histogram\naxes[0].hist(treatment_donors['amount'], bins=30, color='skyblue', alpha=0.7)\naxes[0].axvline(treatment_avg, color='red', linestyle='--', label=f'Avg: {treatment_avg:.2f}')\naxes[0].set_title('Treatment Group: Donation Amounts')\naxes[0].set_xlabel('Donation Amount')\naxes[0].set_ylabel('Frequency')\naxes[0].legend()\n\n# Control group histogram\naxes[1].hist(control_donors['amount'], bins=30, color='pink', alpha=0.7)\naxes[1].axvline(control_avg, color='red', linestyle='--', label=f'Avg: {control_avg:.2f}')\naxes[1].set_title('Control Group: Donation Amounts')\naxes[1].set_xlabel('Donation Amount')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n# Define sample sizes\nsample_sizes = [50, 200, 500, 1000]\n\n# Initialize a figure for subplots\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\naxes = axes.flatten()\n\n# Loop through each sample size\nfor i, sample_size in enumerate(sample_sizes):\n    avg_differences = []\n    \n    # Simulate 1000 averages\n    for _ in range(1000):\n        treatment_sample = np.random.choice(treatment_draws, size=sample_size, replace=True)\n        control_sample = np.random.choice(control_draws, size=sample_size, replace=True)\n        avg_differences.append(np.mean(treatment_sample - control_sample))\n    \n    # Plot histogram\n    axes[i].hist(avg_differences, bins=30, color='pink', edgecolor='black', alpha=0.7)\n    axes[i].axvline(0, color='red', linestyle='--', label='Zero')\n    axes[i].set_title(f'Sample Size: {sample_size}')\n    axes[i].set_xlabel('Average Difference')\n    axes[i].set_ylabel('Frequency')\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n# Calculate means\nmean_r1 = r1['gave'].mean()\nmean_r2 = r2['gave'].mean()\nmean_r3 = r3['gave'].mean()\n\n# Calculate variances\nvar_r1 = r1['gave'].var(ddof=1)\nvar_r2 = r2['gave'].var(ddof=1)\nvar_r3 = r3['gave'].var(ddof=1)\n\n# Calculate sample sizes\nn_r1 = len(r1['gave'])\nn_r2 = len(r2['gave'])\nn_r3 = len(r3['gave'])\n\n# Calculate standard errors\nse_1v2 = ((var_r1 / n_r1) + (var_r2 / n_r2)) ** 0.5\nse_2v3 = ((var_r2 / n_r2) + (var_r3 / n_r3)) ** 0.5\n\n# Calculate t-statistics\nt_stat_1v2 = (mean_r1 - mean_r2) / se_1v2\nt_stat_2v3 = (mean_r2 - mean_r3) / se_2v3\n\n# Degrees of freedom for unequal variances (Welch's t-test)\ndf_1v2 = ((var_r1 / n_r1 + var_r2 / n_r2) ** 2) / \\\n         (((var_r1 / n_r1) ** 2) / (n_r1 - 1) + ((var_r2 / n_r2) ** 2) / (n_r2 - 1))\ndf_2v3 = ((var_r2 / n_r2 + var_r3 / n_r3) ** 2) / \\\n         (((var_r2 / n_r2) ** 2) / (n_r2 - 1) + ((var_r3 / n_r3) ** 2) / (n_r3 - 1))\n\n# Calculate p-values (two-tailed)\np_value_1v2 = 2 * (1 - stats.t.cdf(abs(t_stat_1v2), df_1v2))\np_value_2v3 = 2 * (1 - stats.t.cdf(abs(t_stat_2v3), df_2v3))\n\nprint(f\"T-test 1:1 vs 2:1 - t-statistic: {t_stat_1v2:.4f}, p-value: {p_value_1v2:.4f}\")\nprint(f\"T-test 2:1 vs 3:1 - t-statistic: {t_stat_2v3:.4f}, p-value: {p_value_2v3:.4f}\")\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[16], line 2\n      1 # Calculate means\n----&gt; 2 mean_r1 = r1['gave'].mean()\n      3 mean_r2 = r2['gave'].mean()\n      4 mean_r3 = r3['gave'].mean()\n\nNameError: name 'r1' is not defined\n\n\n\n\n# Create a DataFrame for the T-test results\nt_test_results_df = pd.DataFrame({\n    \"Comparison\": [\"1:1 vs 2:1\", \"2:1 vs 3:1\"],\n    \"T-statistic\": [t_stat_1v2, t_stat_2v3],\n    \"P-value\": [p_value_1v2, p_value_2v3]\n})\n\nprint(t_test_results_df)\n\n\n# Calculate means\nmean_treatment_amount = treatment_amount.mean()\nmean_control_amount = control_amount.mean()\n\n# Calculate variances\nvar_treatment_amount = treatment_amount.var(ddof=1)\nvar_control_amount = control_amount.var(ddof=1)\n\n# Calculate sample sizes\nn_treatment_amount = len(treatment_amount)\nn_control_amount = len(control_amount)\n\n# Calculate the pooled standard error\nse_amount = ((var_treatment_amount / n_treatment_amount) + (var_control_amount / n_control_amount)) ** 0.5\n\n# Calculate the t-statistic\nt_stat_amount_manual = (mean_treatment_amount - mean_control_amount) / se_amount\n\n# Degrees of freedom for unequal variances (Welch's t-test)\ndf_amount = ((var_treatment_amount / n_treatment_amount + var_control_amount / n_control_amount) ** 2) / \\\n    (((var_treatment_amount / n_treatment_amount) ** 2) / (n_treatment_amount - 1) + \n     ((var_control_amount / n_control_amount) ** 2) / (n_control_amount - 1))\n\n# Calculate the p-value (two-tailed)\np_value_amount_manual = 2 * (1 - stats.t.cdf(abs(t_stat_amount_manual), df_amount))\n\nprint(f\"T-test for donation amount (manual): t-statistic = {t_stat_amount_manual:.4f}, p-value = {p_value_amount_manual:.4f}\")\n\n\nt_test_amount_manual_results = pd.DataFrame({\n    \"Metric\": [\"t-statistic\", \"p-value\"],\n    \"Value\": [t_stat_amount_manual.round(4), p_value_amount_manual.round(4)]\n})\n\nprint(t_test_amount_manual_results)\n\n\namount_model_results = pd.DataFrame({\n    \"Metric\": [\"t-statistic\", \"p-value\"],\n    \"Value\": [amount_model.tvalues['treatment'].round(4), amount_model.pvalues['treatment'].round(4)]\n})\n\nprint(amount_model_results)\n\n\ntreatment_coef_df = pd.DataFrame({\n    \"Metric\": [\"Treatment Coefficient\"],\n    \"Value\": [treatment_coef.round(4)]\n})\n\nprint(treatment_coef_df)"
  },
  {
    "objectID": "blog/Project2/hw1_questions.html",
    "href": "blog/Project2/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/Project2/hw1_questions.html#introduction",
    "href": "blog/Project2/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/Project2/hw1_questions.html#data",
    "href": "blog/Project2/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "blog/Project2/hw1_questions.html#experimental-results",
    "href": "blog/Project2/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "blog/Project2/hw1_questions.html#simulation-experiment",
    "href": "blog/Project2/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  }
]