<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.5">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Lulu Ling">
<meta name="dcterms.date" content="2025-06-09">

<title>Dual-Approach Machine Learning Analysis: K-Means Clustering and KNN Classification – Lulu’s Marketing Analytics Project</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ff4371ef257df69894857e99c6ad0d06.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-864d09a486993568dc8461093c99f470.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Lulu’s Marketing Analytics Project</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../Resume.html"> 
<span class="menu-text">Resume</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#a.-k-means" id="toc-a.-k-means" class="nav-link active" data-scroll-target="#a.-k-means">1a. K-Means</a>
  <ul class="collapse">
  <li><a href="#data-organization-and-variable-selection" id="toc-data-organization-and-variable-selection" class="nav-link" data-scroll-target="#data-organization-and-variable-selection">Data organization and variable selection</a></li>
  <li><a href="#custom-k-means-algorithm" id="toc-custom-k-means-algorithm" class="nav-link" data-scroll-target="#custom-k-means-algorithm">Custom K-means algorithm</a></li>
  <li><a href="#visualizing-k-means-clustering-results" id="toc-visualizing-k-means-clustering-results" class="nav-link" data-scroll-target="#visualizing-k-means-clustering-results">Visualizing K-means clustering results</a></li>
  <li><a href="#wcss" id="toc-wcss" class="nav-link" data-scroll-target="#wcss">WCSS</a></li>
  <li><a href="#comparison-with-sklearns-kmeans-results" id="toc-comparison-with-sklearns-kmeans-results" class="nav-link" data-scroll-target="#comparison-with-sklearns-kmeans-results">Comparison with sklearn’s KMeans results</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul></li>
  <li><a href="#b.-latent-class-mnl" id="toc-b.-latent-class-mnl" class="nav-link" data-scroll-target="#b.-latent-class-mnl">1b. Latent-Class MNL</a>
  <ul class="collapse">
  <li><a href="#data-exploring" id="toc-data-exploring" class="nav-link" data-scroll-target="#data-exploring">Data Exploring</a></li>
  <li><a href="#building-a-baseline-multinomial-logit-model-mnl" id="toc-building-a-baseline-multinomial-logit-model-mnl" class="nav-link" data-scroll-target="#building-a-baseline-multinomial-logit-model-mnl">Building a baseline Multinomial Logit model (MNL)</a></li>
  <li><a href="#compare-multi-group-models-using-bic-to-select-the-optimal-number-of-groups" id="toc-compare-multi-group-models-using-bic-to-select-the-optimal-number-of-groups" class="nav-link" data-scroll-target="#compare-multi-group-models-using-bic-to-select-the-optimal-number-of-groups">Compare multi-group models using BIC to select the optimal number of groups</a></li>
  <li><a href="#analyze-the-preference-parameters-and-group-proportions-of-the-best-group-s2" id="toc-analyze-the-preference-parameters-and-group-proportions-of-the-best-group-s2" class="nav-link" data-scroll-target="#analyze-the-preference-parameters-and-group-proportions-of-the-best-group-s2">Analyze the preference parameters and group proportions of the best group (S=2)</a></li>
  </ul></li>
  <li><a href="#a.-k-nearest-neighbors" id="toc-a.-k-nearest-neighbors" class="nav-link" data-scroll-target="#a.-k-nearest-neighbors">2a. K Nearest Neighbors</a>
  <ul class="collapse">
  <li><a href="#generate-training-data-set" id="toc-generate-training-data-set" class="nav-link" data-scroll-target="#generate-training-data-set">Generate training data set</a></li>
  <li><a href="#visual-training-materials-and-boundaries" id="toc-visual-training-materials-and-boundaries" class="nav-link" data-scroll-target="#visual-training-materials-and-boundaries">Visual training materials and boundaries</a></li>
  <li><a href="#generate-test-data-sets-different-random-seeds" id="toc-generate-test-data-sets-different-random-seeds" class="nav-link" data-scroll-target="#generate-test-data-sets-different-random-seeds">Generate test data sets (different random seeds)</a></li>
  <li><a href="#handwritten-knn-classifier" id="toc-handwritten-knn-classifier" class="nav-link" data-scroll-target="#handwritten-knn-classifier">Handwritten KNN Classifier</a></li>
  <li><a href="#compare-to-sklearns-built-in-results" id="toc-compare-to-sklearns-built-in-results" class="nav-link" data-scroll-target="#compare-to-sklearns-built-in-results">Compare to sklearn’s built-in results</a></li>
  <li><a href="#accuracy-performance-for-runs-k-1-to-30" id="toc-accuracy-performance-for-runs-k-1-to-30" class="nav-link" data-scroll-target="#accuracy-performance-for-runs-k-1-to-30">Accuracy performance for runs k = 1 to 30</a></li>
  </ul></li>
  <li><a href="#b.-key-drivers-analysis" id="toc-b.-key-drivers-analysis" class="nav-link" data-scroll-target="#b.-key-drivers-analysis">2b. Key Drivers Analysis</a>
  <ul class="collapse">
  <li><a href="#data-exploring-1" id="toc-data-exploring-1" class="nav-link" data-scroll-target="#data-exploring-1">Data Exploring</a></li>
  <li><a href="#calculate-basic-variable-importance-indicators-pearson-standardized-coefficient-usefulness" id="toc-calculate-basic-variable-importance-indicators-pearson-standardized-coefficient-usefulness" class="nav-link" data-scroll-target="#calculate-basic-variable-importance-indicators-pearson-standardized-coefficient-usefulness">Calculate basic variable importance indicators (Pearson, standardized coefficient, Usefulness)</a></li>
  <li><a href="#advanced-variable-importance-index-analysis-permutation-gini-johnson" id="toc-advanced-variable-importance-index-analysis-permutation-gini-johnson" class="nav-link" data-scroll-target="#advanced-variable-importance-index-analysis-permutation-gini-johnson">Advanced variable importance index analysis (Permutation, Gini, Johnson)</a></li>
  <li><a href="#managerial-implications" id="toc-managerial-implications" class="nav-link" data-scroll-target="#managerial-implications">Managerial Implications</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Dual-Approach Machine Learning Analysis: K-Means Clustering and KNN Classification</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Lulu Ling </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 9, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="a.-k-means" class="level2">
<h2 class="anchored" data-anchor-id="a.-k-means">1a. K-Means</h2>
<section id="data-organization-and-variable-selection" class="level3">
<h3 class="anchored" data-anchor-id="data-organization-and-variable-selection">Data organization and variable selection</h3>
<p>K-means can only process numerical variables, so we need to first select suitable features (in this question, we use beak length and fin length) and remove missing values.</p>
<div id="5f927e09" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Data organization</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>penguins_df<span class="op">=</span>pd.read_csv(<span class="st">"/home/jovyan/Desktop/UCSD/Spring/MGTA495/lulu_marketing_analytics/blog/Project4/palmer_penguins.csv"</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> penguins_df[[<span class="st">"bill_length_mm"</span>, <span class="st">"flipper_length_mm"</span>]].dropna().values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>These two variables are highly heterogeneous in body structure and can help the model to effectively classify the groups. Using .dropna() can ensure data integrity and avoid subsequent errors.</p>
</section>
<section id="custom-k-means-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="custom-k-means-algorithm">Custom K-means algorithm</h3>
<p>Manual implementation allows to deeply understand each step: assigning groups, updating centers, convergence conditions, etc. It can also be used to compare the results with the package.</p>
<div id="7be31af4" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> kmeans(X, k<span class="op">=</span><span class="dv">3</span>, max_iters<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    centroids <span class="op">=</span> X[np.random.choice(<span class="bu">len</span>(X), k, replace<span class="op">=</span><span class="va">False</span>)]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(max_iters):</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        distances <span class="op">=</span> np.linalg.norm(X[:, np.newaxis] <span class="op">-</span> centroids, axis<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> np.argmin(distances, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        new_centroids <span class="op">=</span> np.array([X[labels <span class="op">==</span> j].mean(axis<span class="op">=</span><span class="dv">0</span>) <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(k)])</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.allclose(centroids, new_centroids):</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        centroids <span class="op">=</span> new_centroids</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> labels, centroids</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>labels_custom, centroids_custom <span class="op">=</span> kmeans(data, k<span class="op">=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This program will assign data points to the nearest center based on distance and repeatedly update the center until it stabilizes. You will see that the groups gradually separate clearly after a few iterations.</p>
</section>
<section id="visualizing-k-means-clustering-results" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-k-means-clustering-results">Visualizing K-means clustering results</h3>
<p>K-means is a distance-based algorithm. Visualization can help us understand how the algorithm classifies data.</p>
<ul>
<li>Each cluster is represented by a different color</li>
<li>The red X is the cluster center</li>
<li>You can see how the center points are clustered at the average position of the data within the cluster and show stable cluster boundaries</li>
</ul>
<div id="fa6a6b3f" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Visualizing</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>plt.scatter(data[:, <span class="dv">0</span>], data[:, <span class="dv">1</span>], c<span class="op">=</span>labels_custom, cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>plt.scatter(centroids_custom[:, <span class="dv">0</span>], centroids_custom[:, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>, marker<span class="op">=</span><span class="st">'X'</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"bill_length_mm"</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"flipper_length_mm"</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"K-means clustering results"</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-4-output-1.png" width="593" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="wcss" class="level3">
<h3 class="anchored" data-anchor-id="wcss">WCSS</h3>
<div id="a2fbc270" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>WCSS Visualizing</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-import necessary libraries after code state reset</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_score</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Reload the dataset</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> penguins_df[[<span class="st">"bill_length_mm"</span>, <span class="st">"flipper_length_mm"</span>]].dropna().values</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize lists to store evaluation metrics</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>inertias <span class="op">=</span> []</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>silhouette_scores <span class="op">=</span> []</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>k_range <span class="op">=</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">8</span>)  <span class="co"># Testing K values from 2 to 7</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute metrics for each K</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> k_range:</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> kmeans.fit_predict(data)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    inertias.append(kmeans.inertia_)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    silhouette_scores.append(silhouette_score(data, labels))</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting results</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot WCSS</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>plt.subplot()</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>plt.plot(k_range, inertias, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Within-Cluster Sum of Squares (WCSS)"</span>)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Number of Clusters (K)"</span>)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"WCSS"</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-5-output-1.png" width="610" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>The smaller the value, the closer the points in the cluster are to the center, and the better the clustering effect.</li>
<li>As the number of clusters increases, WCSS will continue to decrease, but the so-called “elbow point” will appear.</li>
<li>Observation: The decline begins to slow down when K=3 or K=4, and K=3 is a reasonable choice. ### Silhouette Score</li>
</ul>
<div id="221040a3" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Silhouette Score Visualizing</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Silhouette Score</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>plt.plot(k_range, silhouette_scores, marker<span class="op">=</span><span class="st">'o'</span>, linestyle<span class="op">=</span><span class="st">'-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, color<span class="op">=</span><span class="st">'#FF8C00'</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>plt.xticks(k_range)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Silhouette Score by Number of Clusters"</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Number of Clusters (K)"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Silhouette Score"</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-6-output-1.png" width="600" height="454" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>Measures the relative distance of each point from its own group vs.&nbsp;neighboring groups, ranging from -1 to 1, with higher values ​​indicating clearer grouping.</li>
<li>Observation: K=2 has the highest score (&gt;0.6), and K=3 has the second highest score (~0.48).</li>
<li>Although K=2 has the highest score, combined with the WCSS inflection point, K=3 achieves a good balance between the contour grouping effect and the WCSS cost.</li>
</ul>
</section>
<section id="comparison-with-sklearns-kmeans-results" class="level3">
<h3 class="anchored" data-anchor-id="comparison-with-sklearns-kmeans-results">Comparison with sklearn’s KMeans results</h3>
<div id="cede3266" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>KMeans Results</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>model_labels <span class="op">=</span> model.fit_predict(data)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>comp_result <span class="op">=</span> pd.DataFrame(data, columns<span class="op">=</span>[<span class="st">"bill_length_mm"</span>, <span class="st">"flipper_length_mm"</span>])</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>comp_result[<span class="st">"KMeans_label"</span>] <span class="op">=</span> model_labels</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>comp_result.head(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="125">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">bill_length_mm</th>
<th data-quarto-table-cell-role="th">flipper_length_mm</th>
<th data-quarto-table-cell-role="th">KMeans_label</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>39.1</td>
<td>181.0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>39.5</td>
<td>186.0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>40.3</td>
<td>195.0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>36.7</td>
<td>193.0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>39.3</td>
<td>190.0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>38.9</td>
<td>181.0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>39.2</td>
<td>195.0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>41.1</td>
<td>182.0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>38.6</td>
<td>191.0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>34.6</td>
<td>198.0</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="fd72f1df" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Sklearn Results</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">6</span>))</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>plt.scatter(data[:, <span class="dv">0</span>], data[:, <span class="dv">1</span>], c<span class="op">=</span>model_labels, cmap<span class="op">=</span><span class="st">'cool'</span>, s<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>plt.scatter(model.cluster_centers_[:, <span class="dv">0</span>], model.cluster_centers_[:, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'black'</span>, marker<span class="op">=</span><span class="st">'X'</span>, s<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"bill_length_mm"</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"flipper_length_mm"</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Sklearn KMeans Clustering Result"</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-8-output-1.png" width="668" height="523" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="d2646658" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Cluster Results</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>unique, counts <span class="op">=</span> np.unique(model_labels, return_counts<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>cluster_summary <span class="op">=</span> <span class="bu">dict</span>(<span class="bu">zip</span>(unique, counts))</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The number of data per group："</span>, cluster_summary)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The number of data per group： {0: 143, 1: 96, 2: 94}</code></pre>
</div>
</div>
</section>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<p>In this analysis, I implemented the K-means clustering algorithm from scratch and applied it to the Palmer Penguins dataset using bill length and flipper length as input features. The algorithm successfully grouped the penguins into three distinct clusters, capturing underlying patterns in their morphology. I then compared my results to those generated by the built-in KMeans function from scikit-learn, and found a high degree of similarity in clustering structure. This not only validated the correctness of my implementation but also provided valuable insights into how feature selection and distance-based clustering can uncover natural groupings within biological data. Overall, this exercise deepened my understanding of unsupervised learning, algorithm design, and exploratory data analysis.</p>
</section>
</section>
<section id="b.-latent-class-mnl" class="level2">
<h2 class="anchored" data-anchor-id="b.-latent-class-mnl">1b. Latent-Class MNL</h2>
<p>This analysis aims to use the Latent-Class Multinomial Logit (LC-MNL) model to analyze consumers’ choice behavior for four yogurt brands, further identify potential market segments, and understand the responses of different categories of consumers to price and promotions.</p>
<ul>
<li>The traditional MNL model assumes that everyone has the same preferences.</li>
<li>The LC-MNL model allows for consumer heterogeneity and estimates the choice tendency of each category through latent groups (segments), and also estimates the probability of each consumer belonging to which group.</li>
</ul>
<section id="data-exploring" class="level3">
<h3 class="anchored" data-anchor-id="data-exploring">Data Exploring</h3>
<p>The model requires structured input data, including candidate brands, attributes, and selection labels for each selection. This program will split the original 4 brand options in each column into 4 columns, so that 1 observation corresponds to 1 brand, and the total number of data columns will be 4 times, which is suitable for choice model analysis.</p>
<div id="af744b70" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Data Preparation</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>df_yogurt <span class="op">=</span> pd.read_csv(<span class="st">"/home/jovyan/Desktop/UCSD/Spring/MGTA495/lulu_marketing_analytics/blog/Project4/yogurt_data.csv"</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>df_long <span class="op">=</span> pd.DataFrame()</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">5</span>):  </span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    temp <span class="op">=</span> pd.DataFrame({</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">'id'</span>: df_yogurt[<span class="st">'id'</span>],</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">'brand'</span>: i,</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">'price'</span>: df_yogurt[<span class="ss">f'p</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>],</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">'feature'</span>: df_yogurt[<span class="ss">f'f</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>],</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">'chosen'</span>: df_yogurt[<span class="ss">f'y</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>]</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    df_long <span class="op">=</span> pd.concat([df_long, temp], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>df_long.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="128">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">brand</th>
<th data-quarto-table-cell-role="th">price</th>
<th data-quarto-table-cell-role="th">feature</th>
<th data-quarto-table-cell-role="th">chosen</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>1</td>
<td>0.108</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>1</td>
<td>0.108</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>1</td>
<td>0.108</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>1</td>
<td>0.108</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>1</td>
<td>0.125</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<ul>
<li>id represents each purchase choice scenario</li>
<li>choice represents the actual chosen brand</li>
<li>brand, price, and feat are attributes of candidate brands</li>
<li>chosen represents whether it is an actual choice (1/0), which is a dependent variable of the MNL model</li>
</ul>
</section>
<section id="building-a-baseline-multinomial-logit-model-mnl" class="level3">
<h3 class="anchored" data-anchor-id="building-a-baseline-multinomial-logit-model-mnl">Building a baseline Multinomial Logit model (MNL)</h3>
<p>Before building the Latent-Class MNL model, we need to estimate a traditional Multinomial Logit (MNL) model as a baseline. This model assumes that all consumers have the same preferences for product attributes (such as price and promotion), and uses this set of “average preferences” to explain the overall market choice behavior.</p>
<p>BIC strikes a balance between log-likelihood performance and parameter complexity: <span class="math inline">\(\text{BIC} = -2 \cdot \ell_n + k \cdot \log(n)\)</span> - <span class="math inline">\(\ell_n\)</span>: log-likelihood of the model (the higher the better) - <span class="math inline">\(k\)</span>: number of parameters (the fewer the better) - <span class="math inline">\(n\)</span>: number of data points (number of samples)</p>
<p>The goal is to find the number of groups with the smallest BIC, which represents the best compromise between performance and simplicity.</p>
<div id="6fdd9c03" class="cell" data-execution_count="10">
<details class="code-fold">
<summary>Model Building</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>df_subset <span class="op">=</span> df_long[df_long[<span class="st">"id"</span>] <span class="op">&lt;=</span> <span class="dv">300</span>].copy()</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>X_sub <span class="op">=</span> df_subset[[<span class="st">"price"</span>, <span class="st">"feature"</span>]].values</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>y_sub <span class="op">=</span> df_subset[<span class="st">"chosen"</span>].values</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>ids_sub <span class="op">=</span> df_subset[<span class="st">"id"</span>].values</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> estimate_lc_mnl_fast(X, y, ids, S<span class="op">=</span><span class="dv">2</span>, T<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    id_map <span class="op">=</span> {v: i <span class="cf">for</span> i, v <span class="kw">in</span> <span class="bu">enumerate</span>(np.unique(ids))}</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    id_idx <span class="op">=</span> np.array([id_map[i] <span class="cf">for</span> i <span class="kw">in</span> ids])</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    num_obs <span class="op">=</span> <span class="bu">len</span>(np.unique(id_idx))</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    J <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    np.random.seed(<span class="dv">0</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> [np.random.randn(X.shape[<span class="dv">1</span>]) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(S)]</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    pi <span class="op">=</span> np.full(S, <span class="dv">1</span> <span class="op">/</span> S)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    responsibilities <span class="op">=</span> np.zeros((num_obs, S))</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> mnl_prob(X, beta):</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>        utilities <span class="op">=</span> X <span class="op">@</span> beta</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>        exp_util <span class="op">=</span> np.exp(utilities <span class="op">-</span> np.<span class="bu">max</span>(utilities))</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> exp_util <span class="op">/</span> np.<span class="bu">sum</span>(exp_util)</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># E-step</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_obs):</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>            probs <span class="op">=</span> []</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> s <span class="kw">in</span> <span class="bu">range</span>(S):</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>                xi <span class="op">=</span> X[id_idx <span class="op">==</span> i]</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>                yi <span class="op">=</span> y[id_idx <span class="op">==</span> i]</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>                pj <span class="op">=</span> mnl_prob(xi, beta[s])</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>                prob <span class="op">=</span> np.prod(pj[yi <span class="op">==</span> <span class="dv">1</span>])</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>                probs.append(pi[s] <span class="op">*</span> prob)</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>            probs <span class="op">=</span> np.array(probs)</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>            responsibilities[i] <span class="op">=</span> probs <span class="op">/</span> np.<span class="bu">sum</span>(probs)</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># M-step</span></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> s <span class="kw">in</span> <span class="bu">range</span>(S):</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>            weights <span class="op">=</span> responsibilities[:, s]</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>            <span class="kw">def</span> neg_log_likelihood(b):</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>                ll <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_obs):</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>                    xi <span class="op">=</span> X[id_idx <span class="op">==</span> i]</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>                    yi <span class="op">=</span> y[id_idx <span class="op">==</span> i]</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>                    pj <span class="op">=</span> mnl_prob(xi, b)</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>                    ll <span class="op">+=</span> weights[i] <span class="op">*</span> np.<span class="bu">sum</span>(yi <span class="op">*</span> np.log(pj <span class="op">+</span> <span class="fl">1e-10</span>))</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> <span class="op">-</span>ll</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>            res <span class="op">=</span> minimize(neg_log_likelihood, beta[s], method<span class="op">=</span><span class="st">'L-BFGS-B'</span>)</span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>            beta[s] <span class="op">=</span> res.x</span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>        pi <span class="op">=</span> responsibilities.mean(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>    ll <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_obs):</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>        xi <span class="op">=</span> X[id_idx <span class="op">==</span> i]</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>        yi <span class="op">=</span> y[id_idx <span class="op">==</span> i]</span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a>        seg_prob <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> s <span class="kw">in</span> <span class="bu">range</span>(S):</span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>            pj <span class="op">=</span> mnl_prob(xi, beta[s])</span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a>            prob <span class="op">=</span> np.prod(pj[yi <span class="op">==</span> <span class="dv">1</span>])</span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a>            seg_prob <span class="op">+=</span> pi[s] <span class="op">*</span> prob</span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a>        ll <span class="op">+=</span> np.log(seg_prob <span class="op">+</span> <span class="fl">1e-10</span>)</span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ll, beta, pi</span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a>bic_results_simplified <span class="op">=</span> []</span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> S <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">6</span>):</span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a>    ll, beta_out, pi_out <span class="op">=</span> estimate_lc_mnl_fast(X_sub, y_sub, ids_sub, S<span class="op">=</span>S, T<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a>    k <span class="op">=</span> S <span class="op">*</span> X_sub.shape[<span class="dv">1</span>] <span class="op">+</span> (S <span class="op">-</span> <span class="dv">1</span>)  <span class="co"># parameters: S * beta + (S - 1) segment proportions</span></span>
<span id="cb11-68"><a href="#cb11-68" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(np.unique(ids_sub))  <span class="co"># number of choice situations</span></span>
<span id="cb11-69"><a href="#cb11-69" aria-hidden="true" tabindex="-1"></a>    bic <span class="op">=</span> <span class="op">-</span><span class="dv">2</span> <span class="op">*</span> ll <span class="op">+</span> k <span class="op">*</span> np.log(n)</span>
<span id="cb11-70"><a href="#cb11-70" aria-hidden="true" tabindex="-1"></a>    bic_results_simplified.append((S, ll, k, bic))</span>
<span id="cb11-71"><a href="#cb11-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-72"><a href="#cb11-72" aria-hidden="true" tabindex="-1"></a>bic_df_simplified <span class="op">=</span> pd.DataFrame(bic_results_simplified, columns<span class="op">=</span>[<span class="st">"NumSegments"</span>, <span class="st">"LogLikelihood"</span>, <span class="st">"NumParameters"</span>, <span class="st">"BIC"</span>])</span>
<span id="cb11-73"><a href="#cb11-73" aria-hidden="true" tabindex="-1"></a>bic_df_simplified.sort_values(by<span class="op">=</span><span class="st">"BIC"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="129">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">NumSegments</th>
<th data-quarto-table-cell-role="th">LogLikelihood</th>
<th data-quarto-table-cell-role="th">NumParameters</th>
<th data-quarto-table-cell-role="th">BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2</td>
<td>-405.501502</td>
<td>5</td>
<td>839.521917</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>3</td>
<td>-405.433649</td>
<td>8</td>
<td>856.497557</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>4</td>
<td>-405.460375</td>
<td>11</td>
<td>873.662358</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>5</td>
<td>-405.491688</td>
<td>14</td>
<td>890.836330</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<ul>
<li>Although increasing the number of groups will slightly increase the model’s log-likelihood, the number of parameters will also increase dramatically.</li>
<li>Therefore, the higher the BIC, the higher the “increase in model complexity” offsets the slight improvement.</li>
<li>Overall, Segment = 2 is currently the best model setting.</li>
</ul>
</section>
<section id="compare-multi-group-models-using-bic-to-select-the-optimal-number-of-groups" class="level3">
<h3 class="anchored" data-anchor-id="compare-multi-group-models-using-bic-to-select-the-optimal-number-of-groups">Compare multi-group models using BIC to select the optimal number of groups</h3>
<p>In the previous step, we used the EM algorithm to build Latent-Class Multinomial Logit (LC-MNL) models for 2, 3, 4, and 5 groups respectively. Each model assumes that the consumer market is composed of different numbers of potential groups (segments) and estimates different preference parameters (β) for each group.</p>
<p>However, the more groups there are, the more parameters there are, and the more complex the model is, there is a possibility of “overfitting”. Therefore, we cannot only use log-likelihood to select a model, but need to use an indicator that considers the accuracy and complexity of the model - BIC (Bayesian Information Criterion).</p>
<p>BIC formula: <span class="math inline">\(\text{BIC} = -2 \cdot \ell_n + k \cdot \log(n)\)</span></p>
<p>The lower the BIC, the better: it means the model remains simple while improving accuracy.</p>
<ul>
<li>Although the model fit (Log-Likelihood) is slightly improved by increasing the number of groups S</li>
<li>But with each additional group, the number of parameters also increases significantly (the model complexity increases)</li>
<li>BIC measures the balance between accuracy and complexity, and BIC is lowest when S=2</li>
</ul>
<p>In the Latent-Class MNL model, the optimal number of groups is 2.This means the market can be divided into two major consumer groups with significantly different preferences. Next, we can analyze the β coefficient and group proportion (π) for these two groups and make further marketing strategy recommendations</p>
</section>
<section id="analyze-the-preference-parameters-and-group-proportions-of-the-best-group-s2" class="level3">
<h3 class="anchored" data-anchor-id="analyze-the-preference-parameters-and-group-proportions-of-the-best-group-s2">Analyze the preference parameters and group proportions of the best group (S=2)</h3>
<p>We use BIC to determine that two groups (S=2) are the best Latent-Class MNL model. Next, we need to: - Sort out the preference parameters β (sensitivity to price and promotion) of the two groups - Draw a graph to compare the preference differences of different groups - Analyze the proportion of each group of consumers in the market (π) - Provide business decision suggestions</p>
<div id="79372f38" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Segment</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>ll, beta, pi <span class="op">=</span> estimate_lc_mnl_fast(X_sub, y_sub, ids_sub, S<span class="op">=</span><span class="dv">2</span>, T<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>segment_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Segment"</span>: [<span class="dv">1</span>, <span class="dv">2</span>],</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Beta_Price"</span>: [beta[<span class="dv">0</span>][<span class="dv">0</span>], beta[<span class="dv">1</span>][<span class="dv">0</span>]],</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Beta_Feature"</span>: [beta[<span class="dv">0</span>][<span class="dv">1</span>], beta[<span class="dv">1</span>][<span class="dv">1</span>]],</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Segment_Probability"</span>: pi</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>segment_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="130">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Segment</th>
<th data-quarto-table-cell-role="th">Beta_Price</th>
<th data-quarto-table-cell-role="th">Beta_Feature</th>
<th data-quarto-table-cell-role="th">Segment_Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>10.601429</td>
<td>-0.074319</td>
<td>0.506933</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>12.834822</td>
<td>1.993827</td>
<td>0.493067</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<ol type="1">
<li>Segment 1</li>
</ol>
<ul>
<li>Very low sensitivity to promotion (β ≈ 0)</li>
<li>Positive but low sensitivity to price</li>
<li>50.3% of the market</li>
<li>Recommended strategy: Emphasize product quality and brand value, no need for excessive promotion</li>
</ul>
<ol start="2" type="1">
<li>Segment 2</li>
</ol>
<ul>
<li>Very high sensitivity to promotion (β ≈ 2.6)</li>
<li>Higher price sensitivity</li>
<li>49.7% of the market</li>
<li>Recommended strategy: Discounts, gifts, and special offers are effective and suitable for short-term promotional stimulation</li>
</ul>
<div id="078ff806" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Visualizing</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create summary DataFrame again for clarity</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>segment_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Segment"</span>: [<span class="dv">1</span>, <span class="dv">2</span>],</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Beta_Price"</span>: [beta[<span class="dv">0</span>][<span class="dv">0</span>], beta[<span class="dv">1</span>][<span class="dv">0</span>]],</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Beta_Feature"</span>: [beta[<span class="dv">0</span>][<span class="dv">1</span>], beta[<span class="dv">1</span>][<span class="dv">1</span>]],</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Segment_Probability"</span>: pi</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting segment-specific betas and segment share</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Bar plot for beta values</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>segment_df.plot(x<span class="op">=</span><span class="st">"Segment"</span>, y<span class="op">=</span>[<span class="st">"Beta_Price"</span>, <span class="st">"Beta_Feature"</span>], kind<span class="op">=</span><span class="st">"bar"</span>, ax<span class="op">=</span>ax[<span class="dv">0</span>])</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_title(<span class="st">"Segment-Specific Preferences"</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_ylabel(<span class="st">"Coefficient (Beta)"</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].set_xlabel(<span class="st">"Segment"</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].legend([<span class="st">"Price"</span>, <span class="st">"Feature"</span>], title<span class="op">=</span><span class="st">"Variable"</span>)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Pie chart for segment probabilities</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].pie(segment_df[<span class="st">"Segment_Probability"</span>], labels<span class="op">=</span>[<span class="ss">f"Segment </span><span class="sc">{</span>s<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> s <span class="kw">in</span> segment_df[<span class="st">"Segment"</span>]],</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>          autopct<span class="op">=</span><span class="st">'</span><span class="sc">%1.1f%%</span><span class="st">'</span>, colors<span class="op">=</span>[<span class="st">"#66c2a5"</span>, <span class="st">"#fc8d62"</span>], startangle<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">1</span>].set_title(<span class="st">"Segment Market Share"</span>)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-13-output-1.png" width="1105" height="469" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ol type="1">
<li>Left: Segment preference comparison chart (bar chart)</li>
</ol>
<ul>
<li>Displays the β coefficient of each Segment (potential group) for price (Price) and promotion (Feature)</li>
<li>Clearly compares the sensitivity of two groups of consumers to different variables</li>
</ul>
<ol start="2" type="1">
<li>Right: Segment market share chart (pie chart)</li>
</ol>
<ul>
<li>Displays the proportion of each potential category in the market (π value)</li>
<li>Segment 1 is about 50.3%, Segment 2 is about 49.7%</li>
</ul>
<p>According to the model results, the market can be divided into two potential consumer groups. Segment 1 is very insensitive to promotions and slightly sensitive to prices. It is recommended to adopt a marketing strategy that emphasizes quality and brand value; while Segment 2 is highly sensitive to both prices and promotions. It is suitable to stimulate purchase intention through promotional means such as discounts and gifts. Since the market share of the two groups is almost the same, it is recommended to adopt a dual-track parallel marketing strategy, designing differentiated messages and plans for different groups to increase the overall market penetration rate.</p>
</section>
</section>
<section id="a.-k-nearest-neighbors" class="level2">
<h2 class="anchored" data-anchor-id="a.-k-nearest-neighbors">2a. K Nearest Neighbors</h2>
<p>We want to create a simulated data set for a binary classification problem, with the following features: - The data has two features (x1, x2) - The class label y is determined by the boundary of x2 &gt; sin(4x1) + x1 (i.e., the classification above and below a wavy line)</p>
<p>Such data can help us test whether the KNN algorithm can effectively handle classification tasks with “non-linear decision boundaries”.</p>
<section id="generate-training-data-set" class="level3">
<h3 class="anchored" data-anchor-id="generate-training-data-set">Generate training data set</h3>
<p>We need a set of data to train the KNN model. This set of data will simulate the situation in the real world where the data and boundaries are not linearly separable.</p>
<div id="2d983ab0" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seed</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, n)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, n)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.column_stack((x1, x2))</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a wiggly boundary</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>boundary <span class="op">=</span> np.sin(<span class="dv">4</span> <span class="op">*</span> x1) <span class="op">+</span> x1</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> (x2 <span class="op">&gt;</span> boundary).astype(<span class="bu">int</span>)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>dat <span class="op">=</span> pd.DataFrame({<span class="st">'x1'</span>: x1, <span class="st">'x2'</span>: x2, <span class="st">'y'</span>: y})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="visual-training-materials-and-boundaries" class="level3">
<h3 class="anchored" data-anchor-id="visual-training-materials-and-boundaries">Visual training materials and boundaries</h3>
<p>Plotting the simulated data set allows us to clearly see the relationship between the distribution of data points and the position of the classification boundary. We randomly generated 100 two-dimensional data (x1, x2), and y was marked as 0 or 1 depending on whether it was above boundary = sin(4 * x1) + x1 (this is a curved “real boundary”). By plotting this boundary and data points, we can visually observe the difficulty of classification.</p>
<div id="cf34e1a6" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Visualizing</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, n)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, n)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>boundary <span class="op">=</span> np.sin(<span class="dv">4</span> <span class="op">*</span> x1) <span class="op">+</span> x1</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> (x2 <span class="op">&gt;</span> boundary).astype(<span class="bu">int</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> pd.DataFrame({<span class="st">'x1'</span>: x1, <span class="st">'x2'</span>: x2, <span class="st">'y'</span>: y})</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">6</span>))</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>plt.scatter(train_df[<span class="st">"x1"</span>], train_df[<span class="st">"x2"</span>], c<span class="op">=</span>train_df[<span class="st">"y"</span>], cmap<span class="op">=</span><span class="st">'coolwarm'</span>, edgecolor<span class="op">=</span><span class="st">'k'</span>)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>x_line <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">300</span>)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>plt.plot(x_line, np.sin(<span class="dv">4</span> <span class="op">*</span> x_line) <span class="op">+</span> x_line, color<span class="op">=</span><span class="st">'black'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">"True Boundary"</span>)</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x1"</span>)</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"x2"</span>)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Training Data and True Boundary"</span>)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-15-output-1.png" width="662" height="523" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Through the graph, we can clearly see how the data points are distributed on both sides of the wiggly boundary, and we can also intuitively judge the difficulty of classification.</p>
</section>
<section id="generate-test-data-sets-different-random-seeds" class="level3">
<h3 class="anchored" data-anchor-id="generate-test-data-sets-different-random-seeds">Generate test data sets (different random seeds)</h3>
<p>The test set is used to verify the model effect on unseen data. Different seeds must be used to avoid data duplication.</p>
<div id="92ef3508" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">99</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>x1_test <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, n)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>x2_test <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, n)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>boundary_test <span class="op">=</span> np.sin(<span class="dv">4</span> <span class="op">*</span> x1_test) <span class="op">+</span> x1_test</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> (x2_test <span class="op">&gt;</span> boundary_test).astype(<span class="bu">int</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> pd.DataFrame({<span class="st">'x1'</span>: x1_test, <span class="st">'x2'</span>: x2_test, <span class="st">'y'</span>: y_test})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="handwritten-knn-classifier" class="level3">
<h3 class="anchored" data-anchor-id="handwritten-knn-classifier">Handwritten KNN Classifier</h3>
<p>By implementing KNN yourself, you can deepen your understanding of the logic of neighbor classification: find the k closest points → majority vote.</p>
<div id="174e02f6" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> knn_predict(x_test, X_train, y_train, k):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> []</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x <span class="kw">in</span> x_test:</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>        distances <span class="op">=</span> np.sqrt(np.<span class="bu">sum</span>((X_train <span class="op">-</span> x)<span class="op">**</span><span class="dv">2</span>, axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>        neighbors <span class="op">=</span> y_train[np.argsort(distances)[:k]]</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>        vote <span class="op">=</span> np.bincount(neighbors).argmax()</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>        y_pred.append(vote)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(y_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="compare-to-sklearns-built-in-results" class="level3">
<h3 class="anchored" data-anchor-id="compare-to-sklearns-built-in-results">Compare to sklearn’s built-in results</h3>
<div id="3d531422" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Compare to sklearn’s built-in results</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>x1_train <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, n)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>x2_train <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, n)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>boundary_train <span class="op">=</span> np.sin(<span class="dv">4</span> <span class="op">*</span> x1_train) <span class="op">+</span> x1_train</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> (x2_train <span class="op">&gt;</span> boundary_train).astype(<span class="bu">int</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> pd.DataFrame({<span class="st">'x1'</span>: x1_train, <span class="st">'x2'</span>: x2_train, <span class="st">'y'</span>: y_train})</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">99</span>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>x1_test <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, n)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>x2_test <span class="op">=</span> np.random.uniform(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, n)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>boundary_test <span class="op">=</span> np.sin(<span class="dv">4</span> <span class="op">*</span> x1_test) <span class="op">+</span> x1_test</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>y_test <span class="op">=</span> (x2_test <span class="op">&gt;</span> boundary_test).astype(<span class="bu">int</span>)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> pd.DataFrame({<span class="st">'x1'</span>: x1_test, <span class="st">'x2'</span>: x2_test, <span class="st">'y'</span>: y_test})</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>model.fit(train_df[[<span class="st">"x1"</span>, <span class="st">"x2"</span>]], train_df[<span class="st">"y"</span>])</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>acc <span class="op">=</span> model.score(test_df[[<span class="st">"x1"</span>, <span class="st">"x2"</span>]], test_df[<span class="st">"y"</span>])</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>knn_result_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Model"</span>: [<span class="st">"sklearn KNN"</span>],</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">"k"</span>: [<span class="dv">5</span>],</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Accuracy"</span>: [<span class="bu">round</span>(acc <span class="op">*</span> <span class="dv">100</span>, <span class="dv">2</span>)]</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>knn_result_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="136">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Model</th>
<th data-quarto-table-cell-role="th">k</th>
<th data-quarto-table-cell-role="th">Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>sklearn KNN</td>
<td>5</td>
<td>90.0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<ul>
<li>We used 5 neighboring points (k=5) to classify the test data</li>
<li>The prediction accuracy is 90%, which means that the model has good recognition ability for nonlinear boundary data</li>
<li>This can be used as a comparison benchmark when we implement “custom KNN” or test different k values ​​later</li>
</ul>
</section>
<section id="accuracy-performance-for-runs-k-1-to-30" class="level3">
<h3 class="anchored" data-anchor-id="accuracy-performance-for-runs-k-1-to-30">Accuracy performance for runs k = 1 to 30</h3>
<p>In the KNN model, the “k value” represents how many neighboring samples each piece of data needs to refer to for classification. Different k values ​​will have a significant impact on the model’s prediction results: - Too small k value: The model is overly dependent on a single neighbor, easily sensitive to noise, and leads to overfitting - Too large k value: The model averages too much information, the boundaries become blurred, and underfitting may occur</p>
<p>By testing the performance of the model with k = 1 to 30 one by one, we can choose an optimal k value that makes the classification accuracy most stable and effective.</p>
<div id="01d5317d" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Performance Visualization</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>accuracies <span class="op">=</span> []</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">31</span>):</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> knn_predict(test_df[[<span class="st">"x1"</span>, <span class="st">"x2"</span>]].values, train_df[[<span class="st">"x1"</span>, <span class="st">"x2"</span>]].values, train_df[<span class="st">"y"</span>].values, k)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    acc <span class="op">=</span> np.mean(y_pred <span class="op">==</span> test_df[<span class="st">"y"</span>].values)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    accuracies.append(acc)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">31</span>), np.array(accuracies) <span class="op">*</span> <span class="dv">100</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"k (number of neighbors)"</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Accuracy (%)"</span>)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"KNN Accuracy vs. k"</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-19-output-1.png" width="585" height="449" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The horizontal axis of the chart is the number of neighbors k, and the vertical axis is the classification accuracy of the test data (Accuracy %). - When k = 1 or 2, the accuracy reaches the highest, about 92% - As k increases, the accuracy shows an overall downward trend - There are occasional fluctuations in the middle (such as k = 16, 24, the accuracy increases slightly) - When k &gt; 20, the accuracy is mostly stable at around 86% ~ 88%</p>
</section>
</section>
<section id="b.-key-drivers-analysis" class="level2">
<h2 class="anchored" data-anchor-id="b.-key-drivers-analysis">2b. Key Drivers Analysis</h2>
<p>Use a variety of variable importance methods to analyze which variables in a set of data have the greatest impact on the target variable (usually a continuous value). Each method represents a “different model assumption and explanation framework”, which can be integrated together to provide a more comprehensive and robust variable screening and insight foundation.</p>
<section id="data-exploring-1" class="level3">
<h3 class="anchored" data-anchor-id="data-exploring-1">Data Exploring</h3>
<div id="9ce7667e" class="cell" data-execution_count="19">
<details class="code-fold">
<summary>Data</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>driver <span class="op">=</span> pd.read_csv(<span class="st">"/home/jovyan/Desktop/UCSD/Spring/MGTA495/lulu_marketing_analytics/blog/Project4/data_for_drivers_analysis.csv"</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>df_head <span class="op">=</span> pd.DataFrame(driver.head())</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>df_head</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="138">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">brand</th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">satisfaction</th>
<th data-quarto-table-cell-role="th">trust</th>
<th data-quarto-table-cell-role="th">build</th>
<th data-quarto-table-cell-role="th">differs</th>
<th data-quarto-table-cell-role="th">easy</th>
<th data-quarto-table-cell-role="th">appealing</th>
<th data-quarto-table-cell-role="th">rewarding</th>
<th data-quarto-table-cell-role="th">popular</th>
<th data-quarto-table-cell-role="th">service</th>
<th data-quarto-table-cell-role="th">impact</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>98</td>
<td>3</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>179</td>
<td>5</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>197</td>
<td>3</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>317</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>356</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="e13acaf8" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Data</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>df_desc <span class="op">=</span> pd.DataFrame(driver.describe())</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>df_desc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="139">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">brand</th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">satisfaction</th>
<th data-quarto-table-cell-role="th">trust</th>
<th data-quarto-table-cell-role="th">build</th>
<th data-quarto-table-cell-role="th">differs</th>
<th data-quarto-table-cell-role="th">easy</th>
<th data-quarto-table-cell-role="th">appealing</th>
<th data-quarto-table-cell-role="th">rewarding</th>
<th data-quarto-table-cell-role="th">popular</th>
<th data-quarto-table-cell-role="th">service</th>
<th data-quarto-table-cell-role="th">impact</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>2553.000000</td>
<td>2553.000000</td>
<td>2553.000000</td>
<td>2553.000000</td>
<td>2553.000000</td>
<td>2553.000000</td>
<td>2553.000000</td>
<td>2553.000000</td>
<td>2553.000000</td>
<td>2553.000000</td>
<td>2553.000000</td>
<td>2553.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>4.857423</td>
<td>8931.480611</td>
<td>3.386604</td>
<td>0.549550</td>
<td>0.461810</td>
<td>0.334508</td>
<td>0.536232</td>
<td>0.451234</td>
<td>0.451234</td>
<td>0.536232</td>
<td>0.467293</td>
<td>0.330983</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std</td>
<td>2.830096</td>
<td>5114.287849</td>
<td>1.172006</td>
<td>0.497636</td>
<td>0.498637</td>
<td>0.471911</td>
<td>0.498783</td>
<td>0.497714</td>
<td>0.497714</td>
<td>0.498783</td>
<td>0.499027</td>
<td>0.470659</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">min</td>
<td>1.000000</td>
<td>88.000000</td>
<td>1.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">25%</td>
<td>3.000000</td>
<td>4310.000000</td>
<td>3.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">50%</td>
<td>4.000000</td>
<td>8924.000000</td>
<td>4.000000</td>
<td>1.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>1.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75%</td>
<td>6.000000</td>
<td>13545.000000</td>
<td>4.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">max</td>
<td>10.000000</td>
<td>18088.000000</td>
<td>5.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
<td>1.000000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<ul>
<li>satisfaction: is the dependent variable (y), with a value range of 1 to 5, indicating customer satisfaction</li>
<li>Other columns such as trust, easy, rewarding, etc. are explanatory variables (X), most of which are binary variables of 0/1</li>
<li>brand, id: used to identify samples, can be used as a basis for grouping or group variables (can be ignored in analysis)</li>
</ul>
</section>
<section id="calculate-basic-variable-importance-indicators-pearson-standardized-coefficient-usefulness" class="level3">
<h3 class="anchored" data-anchor-id="calculate-basic-variable-importance-indicators-pearson-standardized-coefficient-usefulness">Calculate basic variable importance indicators (Pearson, standardized coefficient, Usefulness)</h3>
<p>The purpose of this step is to calculate three common and powerful variable importance indicators from the perspective of linear correlation and linear model, which will help us to have a preliminary understanding of the influence of each variable on satisfaction.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 30%">
<col style="width: 69%">
</colgroup>
<thead>
<tr class="header">
<th>Metric Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Pearson Correlation</strong></td>
<td>Measures the linear relationship between each variable and <code>satisfaction</code> (ignores other variables)</td>
</tr>
<tr class="even">
<td><strong>Standardized Coefficient (β)</strong></td>
<td>Regression coefficients from a standardized linear model, allowing comparison across variables</td>
</tr>
<tr class="odd">
<td><strong>Usefulness (R² Drop)</strong></td>
<td>Drop in model R² when each variable is removed, reflecting its contribution to explanatory power</td>
</tr>
</tbody>
</table>
<div id="b43e438a" class="cell" data-execution_count="21">
<details class="code-fold">
<summary>Variable Importance Indicators</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> driver.drop(columns<span class="op">=</span>[<span class="st">"brand"</span>, <span class="st">"id"</span>, <span class="st">"satisfaction"</span>])</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> driver[<span class="st">"satisfaction"</span>]</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>correlations <span class="op">=</span> X.corrwith(y)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>reg <span class="op">=</span> LinearRegression().fit(X_scaled, y)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>standardized_betas <span class="op">=</span> pd.Series(reg.coef_, index<span class="op">=</span>X.columns)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>base_r2 <span class="op">=</span> reg.score(X_scaled, y)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>usefulness_scores <span class="op">=</span> {}</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> X.columns:</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    cols <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> X.columns <span class="cf">if</span> c <span class="op">!=</span> col]</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    X_subset <span class="op">=</span> X[cols]</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    X_subset_scaled <span class="op">=</span> scaler.fit_transform(X_subset)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    r2 <span class="op">=</span> LinearRegression().fit(X_subset_scaled, y).score(X_subset_scaled, y)</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>    usefulness_scores[col] <span class="op">=</span> base_r2 <span class="op">-</span> r2</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>usefulness_series <span class="op">=</span> pd.Series(usefulness_scores)</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>step2_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Pearson_Correlation"</span>: correlations,</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Standardized_Beta"</span>: standardized_betas,</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Usefulness_R2_Drop"</span>: usefulness_series</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>}).sort_values(by<span class="op">=</span><span class="st">"Usefulness_R2_Drop"</span>, ascending<span class="op">=</span><span class="va">False</span>).<span class="bu">round</span>(<span class="dv">4</span>)</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>step2_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="140">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Pearson_Correlation</th>
<th data-quarto-table-cell-role="th">Standardized_Beta</th>
<th data-quarto-table-cell-role="th">Usefulness_R2_Drop</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">impact</td>
<td>0.2545</td>
<td>0.1505</td>
<td>0.0112</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">trust</td>
<td>0.2557</td>
<td>0.1356</td>
<td>0.0082</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">service</td>
<td>0.2511</td>
<td>0.1036</td>
<td>0.0047</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">appealing</td>
<td>0.2080</td>
<td>0.0396</td>
<td>0.0007</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">differs</td>
<td>0.1848</td>
<td>0.0326</td>
<td>0.0006</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">easy</td>
<td>0.2130</td>
<td>0.0257</td>
<td>0.0003</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">build</td>
<td>0.1919</td>
<td>0.0234</td>
<td>0.0003</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">popular</td>
<td>0.1714</td>
<td>0.0195</td>
<td>0.0002</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">rewarding</td>
<td>0.1946</td>
<td>0.0059</td>
<td>0.0000</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<ol type="1">
<li>Top Contributors:</li>
</ol>
<ul>
<li>Impact, trust, and service consistently rank highest across all three importance metrics.</li>
<li>These variables have strong linear relationships with satisfaction and contribute meaningfully in the regression model.</li>
</ul>
<ol start="2" type="1">
<li>Pearson Correlation:</li>
</ol>
<ul>
<li>trust, impact, and service show the strongest correlations with satisfaction (around 0.25).</li>
</ul>
<ol start="3" type="1">
<li>Standardized Coefficients (β):</li>
</ol>
<ul>
<li>impact (0.15) and trust (0.14) are the most influential variables after accounting for all others.</li>
</ul>
<ol start="4" type="1">
<li>Usefulness (R² Drop):</li>
</ol>
<ul>
<li>Removing impact, trust, or service causes the largest drop in model R², indicating their key role in explaining satisfaction.</li>
<li>Variables like rewarding, popular, and build show very low importance across all measures.</li>
</ul>
<p>Across all three importance measures, impact, trust, and service are the most valuable drivers of satisfaction. These should be prioritized in managerial focus and communication strategies. The remaining variables may still contribute indirectly or interactively but offer limited individual explanatory power in this linear framework.</p>
</section>
<section id="advanced-variable-importance-index-analysis-permutation-gini-johnson" class="level3">
<h3 class="anchored" data-anchor-id="advanced-variable-importance-index-analysis-permutation-gini-johnson">Advanced variable importance index analysis (Permutation, Gini, Johnson)</h3>
<p>In the previous step, we evaluated the relationship between variables and satisfaction from the perspective of linear models. However, in practice, there may be nonlinear relationships and interactions between variables. For this reason, we introduce the following three more advanced and flexible methods:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 28%">
<col style="width: 71%">
</colgroup>
<thead>
<tr class="header">
<th>Metric Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Permutation Importance</strong></td>
<td>Measures the impact on model performance when a variable is randomly shuffled, reflecting its “replaceability”</td>
</tr>
<tr class="even">
<td><strong>Gini Importance</strong></td>
<td>Based on random forests; sums the decrease in impurity caused by each variable during tree splits</td>
</tr>
<tr class="odd">
<td><strong>Johnson’s Relative Weights</strong></td>
<td>Uses standardized regression coefficients squared to estimate each variable’s relative contribution to explained variance</td>
</tr>
</tbody>
</table>
<div id="3cca0cbc" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Comparison Table</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> permutation_importance</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> driver.drop(columns<span class="op">=</span>[<span class="st">"brand"</span>, <span class="st">"id"</span>, <span class="st">"satisfaction"</span>])</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> driver[<span class="st">"satisfaction"</span>]</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> LinearRegression().fit(X, y)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>perm_importance <span class="op">=</span> permutation_importance(lr, X, y, n_repeats<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>perm_importance_series <span class="op">=</span> pd.Series(perm_importance.importances_mean, index<span class="op">=</span>X.columns)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>rf <span class="op">=</span> RandomForestRegressor(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>rf.fit(X, y)</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>gini_importance <span class="op">=</span> pd.Series(rf.feature_importances_, index<span class="op">=</span>X.columns)</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>lr_std <span class="op">=</span> LinearRegression().fit(X_scaled, y)</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>johnson_weights <span class="op">=</span> pd.Series(lr_std.coef_ <span class="op">**</span> <span class="dv">2</span>, index<span class="op">=</span>X.columns)</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>johnson_weights <span class="op">/=</span> johnson_weights.<span class="bu">sum</span>()</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>step3_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Permutation_Importance"</span>: perm_importance_series,</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Gini_Importance"</span>: gini_importance,</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Johnson_Weights"</span>: johnson_weights</span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>}).sort_values(by<span class="op">=</span><span class="st">"Permutation_Importance"</span>, ascending<span class="op">=</span><span class="va">False</span>).<span class="bu">round</span>(<span class="dv">4</span>)</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>step3_df.reset_index(inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>step3_df.rename(columns<span class="op">=</span>{<span class="st">"index"</span>: <span class="st">"Variable"</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<ul>
<li>Impact, trust, and service are stable drivers that rank at the top in all indicators.</li>
<li>Impact has the highest Johnson Weights (40.4%) and also performs well in permutation and Gini.</li>
<li>Trust ranks highest in Gini importance, indicating that it is particularly critical in the tree model.</li>
<li>Low-impact variables such as rewarding, popular, and build perform weakly in all three indicators.</li>
</ul>
<div id="e69b1be1" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Comparison Table</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Re-import required libraries after reset</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> permutation_importance</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>driver <span class="op">=</span> pd.read_csv(<span class="st">"/home/jovyan/Desktop/UCSD/Spring/MGTA495/lulu_marketing_analytics/blog/Project4/data_for_drivers_analysis.csv"</span>)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> driver.drop(columns<span class="op">=</span>[<span class="st">"brand"</span>, <span class="st">"id"</span>, <span class="st">"satisfaction"</span>])</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> driver[<span class="st">"satisfaction"</span>]</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2 metrics</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Pearson</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>correlations <span class="op">=</span> X.corrwith(y)</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardized beta</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>reg <span class="op">=</span> LinearRegression().fit(X_scaled, y)</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>standardized_betas <span class="op">=</span> pd.Series(reg.coef_, index<span class="op">=</span>X.columns)</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Usefulness</span></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>base_r2 <span class="op">=</span> reg.score(X_scaled, y)</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>usefulness_scores <span class="op">=</span> {}</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> X.columns:</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    cols <span class="op">=</span> [c <span class="cf">for</span> c <span class="kw">in</span> X.columns <span class="cf">if</span> c <span class="op">!=</span> col]</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>    X_subset_scaled <span class="op">=</span> scaler.fit_transform(X[cols])</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>    r2 <span class="op">=</span> LinearRegression().fit(X_subset_scaled, y).score(X_subset_scaled, y)</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>    usefulness_scores[col] <span class="op">=</span> base_r2 <span class="op">-</span> r2</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>usefulness_series <span class="op">=</span> pd.Series(usefulness_scores)</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>step2_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Pearson_Correlation"</span>: correlations,</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Standardized_Beta"</span>: standardized_betas,</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Usefulness_R2_Drop"</span>: usefulness_series</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>}).<span class="bu">round</span>(<span class="dv">4</span>).reset_index().rename(columns<span class="op">=</span>{<span class="st">"index"</span>: <span class="st">"Variable"</span>})</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3 metrics</span></span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Permutation Importance</span></span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> LinearRegression().fit(X, y)</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>perm_importance <span class="op">=</span> permutation_importance(lr, X, y, n_repeats<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a>perm_series <span class="op">=</span> pd.Series(perm_importance.importances_mean, index<span class="op">=</span>X.columns)</span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Gini Importance</span></span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a>rf <span class="op">=</span> RandomForestRegressor(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>rf.fit(X, y)</span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>gini_series <span class="op">=</span> pd.Series(rf.feature_importances_, index<span class="op">=</span>X.columns)</span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Johnson Weights</span></span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>X_scaled <span class="op">=</span> scaler.fit_transform(X)</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a>lr_std <span class="op">=</span> LinearRegression().fit(X_scaled, y)</span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a>johnson_weights <span class="op">=</span> pd.Series(lr_std.coef_ <span class="op">**</span> <span class="dv">2</span>, index<span class="op">=</span>X.columns)</span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a>johnson_weights <span class="op">/=</span> johnson_weights.<span class="bu">sum</span>()</span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a>step3_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Permutation_Importance"</span>: perm_series,</span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Gini_Importance"</span>: gini_series,</span>
<span id="cb24-59"><a href="#cb24-59" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Johnson_Weights"</span>: johnson_weights</span>
<span id="cb24-60"><a href="#cb24-60" aria-hidden="true" tabindex="-1"></a>}).<span class="bu">round</span>(<span class="dv">4</span>).reset_index().rename(columns<span class="op">=</span>{<span class="st">"index"</span>: <span class="st">"Variable"</span>})</span>
<span id="cb24-61"><a href="#cb24-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-62"><a href="#cb24-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge Step 2 and Step 3</span></span>
<span id="cb24-63"><a href="#cb24-63" aria-hidden="true" tabindex="-1"></a>final_df <span class="op">=</span> pd.merge(step2_df, step3_df, on<span class="op">=</span><span class="st">"Variable"</span>).sort_values(by<span class="op">=</span><span class="st">"Permutation_Importance"</span>, ascending<span class="op">=</span><span class="va">False</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-64"><a href="#cb24-64" aria-hidden="true" tabindex="-1"></a>final_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="142">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Variable</th>
<th data-quarto-table-cell-role="th">Pearson_Correlation</th>
<th data-quarto-table-cell-role="th">Standardized_Beta</th>
<th data-quarto-table-cell-role="th">Usefulness_R2_Drop</th>
<th data-quarto-table-cell-role="th">Permutation_Importance</th>
<th data-quarto-table-cell-role="th">Gini_Importance</th>
<th data-quarto-table-cell-role="th">Johnson_Weights</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>impact</td>
<td>0.2545</td>
<td>0.1505</td>
<td>0.0112</td>
<td>0.0332</td>
<td>0.1408</td>
<td>0.4041</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>trust</td>
<td>0.2557</td>
<td>0.1356</td>
<td>0.0082</td>
<td>0.0273</td>
<td>0.1559</td>
<td>0.3283</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>service</td>
<td>0.2511</td>
<td>0.1036</td>
<td>0.0047</td>
<td>0.0165</td>
<td>0.1297</td>
<td>0.1915</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>appealing</td>
<td>0.2080</td>
<td>0.0396</td>
<td>0.0007</td>
<td>0.0025</td>
<td>0.0855</td>
<td>0.0281</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>differs</td>
<td>0.1848</td>
<td>0.0326</td>
<td>0.0006</td>
<td>0.0017</td>
<td>0.0899</td>
<td>0.0190</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>build</td>
<td>0.1919</td>
<td>0.0234</td>
<td>0.0003</td>
<td>0.0010</td>
<td>0.1023</td>
<td>0.0098</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>easy</td>
<td>0.2130</td>
<td>0.0257</td>
<td>0.0003</td>
<td>0.0010</td>
<td>0.0999</td>
<td>0.0118</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>popular</td>
<td>0.1714</td>
<td>0.0195</td>
<td>0.0002</td>
<td>0.0004</td>
<td>0.0949</td>
<td>0.0068</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>rewarding</td>
<td>0.1946</td>
<td>0.0059</td>
<td>0.0000</td>
<td>0.0001</td>
<td>0.1011</td>
<td>0.0006</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="69365536" class="cell" data-execution_count="24">
<details class="code-fold">
<summary>Comparison Plot</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>) </span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data for plotting</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>plot_df <span class="op">=</span> final_df.set_index(<span class="st">"Variable"</span>)[[</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Permutation_Importance"</span>, <span class="st">"Gini_Importance"</span>, <span class="st">"Johnson_Weights"</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>]]</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the importance scores as a grouped horizontal bar chart</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>plot_df.plot(kind<span class="op">=</span><span class="st">"barh"</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>), width<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Comparison of Variable Importance Metrics"</span>)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Importance Score"</span>)</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Variable"</span>)</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>plt.legend(title<span class="op">=</span><span class="st">"Metric"</span>)</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>plt.gca().invert_yaxis()  <span class="co"># Show most important variables on top</span></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-25-output-1.png" width="949" height="564" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Based on the consolidated table and comparative visualization, the top three variables—impact, trust, and service—consistently emerge as the most important drivers of customer satisfaction across all evaluation methods. These variables not only show the strongest Pearson correlations and standardized regression coefficients but also yield the highest scores in permutation importance, Gini index from random forest, and Johnson’s relative weights.</p>
<ul>
<li>Impact stands out as the most influential variable, with the highest Johnson weight (over 40%) and top-ranked permutation importance.</li>
<li>Trust ranks second overall, especially dominant in tree-based models (highest Gini importance).</li>
<li>Service maintains a strong and stable position across all linear and nonlinear measures.</li>
</ul>
<p>On the other hand, variables like rewarding, popular, and build consistently appear at the bottom, indicating relatively low predictive value in explaining satisfaction in this context.</p>
<p>Recommendation: Strategic efforts should prioritize reinforcing the perceived impact, trustworthiness, and quality of service associated with the brand, as these are most likely to drive meaningful improvements in customer satisfaction.</p>
</section>
<section id="managerial-implications" class="level3">
<h3 class="anchored" data-anchor-id="managerial-implications">Managerial Implications</h3>
<ol type="1">
<li>Top Priority Drivers</li>
</ol>
<ul>
<li>impact、trust、service consistently appear as top drivers across all methods.</li>
<li>These dimensions should be the core focus of marketing communication, product messaging, and customer engagement efforts.</li>
</ul>
<ol start="2" type="1">
<li>Low-Impact Factors</li>
</ol>
<ul>
<li>Variables like rewarding, popular, and build show minimal influence across models.</li>
<li>These may be de-prioritized or reframed, unless they serve niche segments or non-satisfaction outcomes.</li>
</ul>
<ol start="3" type="1">
<li>Strategic Recommendations</li>
</ol>
<ul>
<li>Invest in initiatives that reinforce customer trust, such as transparency, testimonials, and ethical branding.</li>
<li>Emphasize service quality through employee training, faster response times, and better omnichannel support.</li>
<li>Highlight perceived impact by showing measurable results and customer transformations.</li>
</ul>
<ol start="4" type="1">
<li>Measurement Plan</li>
</ol>
<ul>
<li>Future campaigns should track these top drivers as KPIs alongside satisfaction.</li>
<li>Consider A/B testing improvements in these variables to validate causal impact.</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>